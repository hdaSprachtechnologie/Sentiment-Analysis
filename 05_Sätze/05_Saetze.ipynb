{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse auf Satzebene\n",
    "\n",
    "Bisher haben wir uns ganze Dokumente angesehen und eine Entscheidung \n",
    "getroffen, ob dieses Dokument eine positive, negative oder neutrale \n",
    "Meinungsäußerung enthält. Diese Entscheidung beruht auf dem \n",
    "Vorhandensein von Sentiment-Wörtern, Negations- und Verstärkungswörtern \n",
    "im Text, ohne dass die syntaktische Struktur beachtet wird. Für kurze \n",
    "Texte wie Tweets ist das eine sinnvolle Herangehensweise. Manchmal wird \n",
    "man aber komplexere Texte betrachten wollen. Bewertungen von Büchern \n",
    "sind oft wesentlich ausführlicher und bestehen aus mehreren Sätzen. \n",
    "Andere Anwendungen von Sentiment-Analyse wollen z. B. die Bewertungen von \n",
    "politischen Ereignissen durch Politiker analysieren, indem Politikerreden analysiert \n",
    "werden. Ein anderes Anwendungsbeispiel ist die Analyse der Bewertungen einer Partei in Zeitungsartikeln. Dies sind komplexe Fälle, bei denen in einem Satz etwas \n",
    "Positives und im nächsten Satz etwas Negatives stehen kann. \n",
    "\n",
    "Sehen wir uns den Anfang einer Buchrezension auf Amazon an (https://www.amazon.de/product-reviews/B07G4PDB9R):\n",
    "\n",
    "*Grundsätzlich ist Sebastian Löbners Einführung in die Semantik \n",
    "empfehlenswert. In 10 Kapiteln, die noch weiter unterteilt sind, werden \n",
    "die grundlegenden Aspekte der Semantik angerissen und vertieft. Am Ende \n",
    "der Kapitel gibt es dann noch weiterführende bzw. erläuternde \n",
    "Literaturempfehlungen und Übungsaufgaben.*\n",
    "\n",
    "*Löbner ist Professor für Sprachwissenschaft und das merkt man beim Lesen \n",
    "des Buches: er weiß, wovon er spricht, das Thema wird gut vertieft, \n",
    "jedoch merkt man es auch an seiner oft umständlichen und komplizierten \n",
    "Sprache. Da hilft es dann auch nicht mehr, dass das ganze Buch sehr \n",
    "übersichtlich gestaltet ist und man oft veranschaulichende Grafiken und \n",
    "Tabellen vorgesetzt bekommt. Wenn der erläuternde Text dazu in \n",
    "verschachtelten Sätzen serviert wird und man sich das Ganze mehrere Male \n",
    "durchlesen muss, ist es trotzdem schwer zu verstehen. Jedoch sind die \n",
    "Grafiken und Tabellen sehr gut und dienen sicherlich dazu, das Thema \n",
    "besser zu verstehen.*\n",
    "\n",
    "*Löbner bringt häufig Beispiele, anhand derer er seine Theorien \n",
    "erläutert. Das ist jedoch auch ein Manko des Buches. Oft stehen \n",
    "Beispiele für sich selbst und werden nicht explizit erläutert.*\n",
    "\n",
    "Es gibt darin einige Sätze, die nicht bewertend sind, wie: \n",
    "\n",
    "*In 10 Kapiteln, die noch weiter unterteilt sind, werden die \n",
    "grundlegenden Aspekte der Semantik angerissen und vertieft.* \n",
    "\n",
    "In diesem einen Dokument sind positive und negative\n",
    "Meinungsäußerungen wie:\n",
    "\n",
    "*Grundsätzlich ist Sebastian Löbners Einführung \n",
    "in die Semantik empfehlenswert.*\n",
    "\n",
    "und \n",
    "\n",
    "*Das ist jedoch auch ein Manko des Buches.* \n",
    "\n",
    "Problematisch dabei ist, dass in einem Satz sowohl \n",
    "Positives als auch Negatives geäußert werden kann, wie:\n",
    "\n",
    "*Löbner ist Professor für Sprachwissenschaft und das merkt man beim Lesen \n",
    "des Buches: er weiß, wovon er spricht, das Thema wird gut vertieft, \n",
    "jedoch merkt man es auch an seiner oft umständlichen und komplizierten \n",
    "Sprache.* \n",
    "\n",
    "Das zeigt, dass auch die Satzebene nicht ausreicht, um \n",
    "die Meinung zu analysieren. Dennoch nehmen wir im Moment an, dass ein \n",
    "Satz nur eine Meinungsäußerung enthalten kann.\n",
    "\n",
    "Um die Aufgabe der Sentiment-Analyse auf Satzebene zu lösen, muss der \n",
    "Text zunächst in Sätze unterteilt werden - die Satz-Tokenisierung. Für \n",
    "jeden Satz muss dann entschieden werden, ob er eine Meinungsäußerung \n",
    "enthält. Schließlich muss analysiert werden, ob diese Meinungsäußerung \n",
    "positiv, negativ oder neutral ist. Dabei werden Negationen und Gradpartikeln in die Analyse einbezogen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satz-Tokenisierung\n",
    "\n",
    "Bei der Satz-Tokenisierung geht es darum, den Text in Sätze aufzuteilen, \n",
    "die dann einzeln analysiert werden können. Man könnte jetzt denken, dass \n",
    "dieses Problem ganz einfach zu lösen ist, indem man immer am Punkt das \n",
    "Ende eines Satzes annimmt. Allerdings gibt es auch in unserem Beispiel \n",
    "Abkürzungen wie  \"bzw.\" oder  \"z. B.\", in denen der Punkt Teil des Tokens \n",
    "ist und kein Satzende markiert. Es ist daher erforderlich, Listen von \n",
    "Tokens anzulegen, die einen Punkt in der Mitte (wie  \"o.ä.\") oder am \n",
    "Ende (wie  \"ca.\") haben, um diese als Ausnahmen beachten zu können. \n",
    "\n",
    "Heyer et al. (2006) geben darüber hinaus Regeln für die \n",
    "Satz-Tokenisierung.\n",
    "\n",
    "Regeln für den Satzanfang:\n",
    "- Sätze beginnen niemals mit Kleinbuchstaben.\n",
    "- Nach einer Überschrift beginnt ein neuer Satz.\n",
    "- Am Anfang eines Absatzes beginnt ein neuer Satz.\n",
    "- Groß geschriebene Artikel (wie  \"Der\",  \"Die\",  \"Den\", ...) sprechen für den Satzanfang.\n",
    "- Beginnt kein neuer Absatz, so steht vor dem neuen Satz ein Satzendezeichen.\n",
    "\n",
    "Regeln für das Satzende:\n",
    "- Sätze enden mit einem Satzendezeichen. Solche Satzendezeichen sind Punkt, Fragezeichen und Ausrufezeichen. Nach dem Satzendezeichen muss zusätzlich ein white space (meist ein Leerzeichen, s.u.) stehen. Achtung, Punkte können auch an anderer Stelle stehen, z. B. nach Abkürzungen oder Zahlen.\n",
    "- Vor einer Überschrift endet ein Satz.\n",
    "- Am Ende eines Absatzes endet ein Satz.\n",
    "- Überschriften sollen wie Sätze behandelt werden.\n",
    "\n",
    "Sprachverarbeitende Module wie spaCy haben oft eine eingebaute \n",
    "Satz-Tokenisierung, die auf ähnliche Weise funktioniert. Testen wir doch \n",
    "einmal den Satz-Tokenisierer von spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "loebner_document= '''Grundsätzlich ist Sebastian Löbners Einführung in die Semantik empfehlenswert. In 10 Kapiteln, die noch weiter unterteilt sind, werden  die grundlegenden Aspekte der Semantik angerissen und vertieft. Am Ende der Kapitel gibt es dann noch weiterführende bzw. erläuternde Literaturempfehlungen und Übungsaufgaben. \n",
    "Löbner ist Professor für Sprachwissenschaft und das merkt man beim Lesen des Buches: er weiß, wovon er spricht, das Thema wird gut vertieft, jedoch merkt man es auch an seiner oft umständlichen und komplizierten Sprache. Da hilft es dann auch nicht mehr, dass das ganze Buch sehr übersichtlich gestaltet ist und man oft veranschaulichende Grafiken und Tabellen vorgesetzt bekommt. Wenn der erläuternde Text dazu in verschachtelten Sätzen serviert wird und man sich das Ganze mehrere Male durchlesen muss, ist es trotzdem schwer zu verstehen. Jedoch sind die Grafiken und Tabellen sehr gut und dienen sicherlich dazu, das Thema besser zu verstehen.\n",
    "Löbner bringt häufig Beispiele, anhand derer er seine Theorien erläutert. Das ist jedoch auch ein Manko des Buches. Oft stehen Beispiele für sich selbst und werden nicht explizit erläutert.'''\n",
    "\n",
    "ana = nlp(loebner_document)\n",
    "\n",
    "for sent in ana.sents:\n",
    "    print(str(sent) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Punkt in der Abkürzung \"bzw.\" wird richtig als Teil des Tokens \n",
    "und nicht als Satzendepunkt verstanden. Tatsächlich gibt es im Quellcode von spaCy\n",
    "eine Datei  \"tokenizer_exceptions.py\" mit Abkürzungen, in der diese \n",
    "Zeile steht:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " {ORTH: `bzw.', LEMMA: `beziehungsweise', NORM: `beziehungsweise'},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist möglich, diese Liste zu erweitern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifikation von Sätzen mit Meinungsäußerungen\n",
    "\n",
    "Auf der Dokumentebene ist oft schon durch den Kontext gegeben, dass das \n",
    "Dokument eine Bewertung enthält. Bei Produktrezensionen ist es sehr \n",
    "unwahrscheinlich, objektive (nur beschreibende) Dokumente zu haben. Auf \n",
    "der Satzebene ist das jedoch anders, denn nicht jeder Satz in einer \n",
    "Rezension enthält auch eine Bewertung. Daher steht am Anfang eine \n",
    "Klassifikation von Sätzen als subjektiv oder objektiv. \n",
    "\n",
    "Annotierte Daten auf der Satzebene sind sehr viel seltener als die auf \n",
    "der Dokumentebene. Wenn man welche hat, kann man die Supervised \n",
    "Learning-Verfahren darauf anwenden. Features dafür sind die Anzahl der \n",
    "Pronomen, Adjektive und Modalverben oder auch die Anzahl der Wörter, die \n",
    "in einem Sentiment-Wörterbuch gesammelt sind; genau wie beim Umgang mit Dokumenten. Eine andere Möglichkeit \n",
    "ist die, Sätze auf ihre Ähnlichkeit mit bereits annotierten Sätzen zu \n",
    "prüfen. Wenn im Trainingskorpus z. B. steht  \"Das Auto finde ich gut.\" \n",
    "und jetzt der Satz \"Dieses Telefon finde ich gut.\" analysiert werden \n",
    "muss, kann der neue Satz als ähnlich dem Trainingssatz identifiziert \n",
    " und damit gleich klassifiziert werden.\n",
    "\n",
    "Ohne annotierte Daten (\"unsupervised\") sucht man nach bewertenden \n",
    "Phrasen im Text. Diese Phrasen werden in einem Lexikon gesammelt. \n",
    "Weiterhin untersucht man die Adjektive: Besonders graduierbare Adjektive\n",
    "(solche mit Steigerungsformen) deuten auf subjektive Sätze hin. Eine \n",
    "Auswertung von Hashtags und Emoticons kann hier ebenfalls weiterhelfen. \n",
    "Schließlich werden auch die Satzstrukturen untersucht: Konditionalsätze \n",
    "(die z. B. mit  \"wenn\" beginnen) oder Fragesätze beinhalten eher keine \n",
    "Meinungsäußerung:\n",
    "\n",
    "*Wenn ich ein gutes Buch darüber kennen würde, würde ich es sofort kaufen.*\n",
    "\n",
    "*Kennst Du ein gutes Buch zu diesem Thema?*\n",
    "\n",
    "Diese Klassifikation ist aber abhängig von der Domäne der Dokumente. \n",
    "Gerade in Social Media-Daten können Fragesätze durchaus subjektiv sein:\n",
    "\n",
    "\n",
    "*RT @Banane0711: @danintown Warum durfte die Bahn am Nordbahnhof ungehindert mehrere Tausend Eidechsen töten?*\n",
    "\n",
    "*Kann man diesen ganzen Scheiß noch glauben..?*\n",
    "\n",
    "*#S21 # Bahn #Rückbau - nein, doch, oh - ist nicht barrierefrei. War der Zensor \"beantworte die Frage nicht!\" pinkeln?*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satzanalyse\n",
    "\n",
    "Wenn die subjektiven Sätze im Dokument identifiziert worden sind, sind \n",
    "die Verfahren der Klassifikation zunächst dieselben wie die Verfahren \n",
    "zur Klassifikation von Dokumenten. Auf Satzebene wird jedoch der Kontext interessant, in dem sich die Sentiment-Wörter befinden. Dabei gibt es  zwei \n",
    "Analysebereiche, die die Genauigkeit der Sentiment-Analyse beeinflussen: \n",
    "Gradpartikeln und Negationen. Da Gradpartikeln und Negationen im Zusammenhang mit weiteren Wörtern im Satz interpretiert werden müssen, spricht man hier von semantischer Kompositionalität.\n",
    "\n",
    "Gradpartikeln stehen zusammen mit Adjektiven und Adverbien und geben die \n",
    "Intensität der Bewertung an. Zum Beispiel:\n",
    "\n",
    "*Ich finde das Produkt sehr schlecht.*\n",
    "\n",
    "Meistens verstärken sie das Adjektiv oder Adverb, das sie modifizieren. \n",
    "Abschwächende Gradpartikeln sind jedoch auch möglich:\n",
    "\n",
    "*Das ist ein bisschen ungünstig.*\n",
    "\n",
    " Für die Erkennung günstig ist, dass sie meistens direkt vor dem \n",
    "bewertenden Adjektiv oder Adverb stehen. \n",
    "\n",
    "Bei Negationen ist der Normalfall, dass die Polarität umgedreht wird. So \n",
    "ist  \"nicht gut\" eben das Gegenteil von  \"gut\". Aber Achtung: \n",
    "\"nicht so gut\" ist nur eine abgeschwächte Form von  \"gut\", nicht \n",
    "das Gegenteil.\n",
    "\n",
    "Negation wird nicht nur durch das Wort \"nicht\" ausgedrückt, sondern \n",
    "kann auch in anderen Formen auftreten. Hier sind einige Beispiele:\n",
    "- *Mir hat es keinen Spaß gemacht.*\n",
    "- *Mir macht es nie Spaß.*\n",
    "- *Niemandem macht das Spaß.*\n",
    "- *Ich denke nicht, dass mir das Spaß macht.*\n",
    "\n",
    "Christopher Potts schlägt eine einfache Methode vor, um mit Negationen \n",
    "umzugehen, die man auf Gradpartikeln übertragen kann (http://sentiment.christopherpotts.net/lingstruc.html\\# negation): Sobald eine \n",
    "Negation im Satz auftritt, wird jedem Wort zwischen der Negation und dem \n",
    "nächsten Satzzeichen ein *_NEG* angehängt. Dadurch entstehen zwei ganz \n",
    "unterschiedliche Tokens  \"gut\" und  \"gut\\_NEG\", die dann auch \n",
    "unterschiedlich analysiert werden können. \n",
    "\n",
    "Wir sehen aber schon an den Beispielen mit Negationen, dass diese Methode vor allem für die deutsche Sprache\n",
    "nicht immer funktioniert: Im letzten Beispiel ist das subjektive Wort \n",
    "\"Spaß\" von der Negation durch ein Komma getrennt. Gerade für Sätze \n",
    "mit  \"dass\" müssen für das Deutsche andere Regeln aufgestellt werden. Ein \n",
    "anderes Problem ist die Wortstellung im Deutschen: Die Negation kann \n",
    "durchaus hinter dem bewertenden Wort stehen:  *Spaß hat dabei wirklich \n",
    "niemand*. Auch Gradpartikeln können an anderer Stelle als direkt vor \n",
    "dem bewertenden Wort stehen:  *Das interessiert mich wirklich sehr.*\n",
    "Auch Schulz et al. (2017) stellen fest, dass für Negationen komplexere Verfahren notwendig sind: \n",
    "\n",
    "*Also, instead of just switching the polarity\n",
    "of a word based on the existence of negation words,\n",
    "a more fine-grained approach would be meaningful.*\n",
    "\n",
    "(dt.: *Anstatt nur die Polarität eines Wortes auf Basis der Existenz von Negationswörtern zu wechseln, wäre ein feinkörnigerer Ansatz sinnvoll.* (eigene Übersetzung))\n",
    "\n",
    "Eine Grammatikanalyse der Sätze gibt die notwendige Information, um den \n",
    "Skopus (den Wirkungsbereich) von Negationen und Gradpartikeln zu bestimmen. \n",
    "\n",
    "SpaCy\\index{spaCy} bietet eine einfachere Dependenzanalyse. Eine Dependenzanalyse geht vom Verb im Satz aus und stellt die Abhängigkeiten der Wörter zueinander in einer Baumstruktur dar. Siehe dazu auch  Carstensen et al. (2009, S. 281f.), mit der die \n",
    "Abhängigkeiten der Wörter untereinander im Text analysiert werden. Für \n",
    "den Satz \"Das Handy ist nicht gut\" bekommen wir diese Analyse:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Das Handy ist nicht gut\")\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Negation hat hier unter \"Head\" das Adjektiv \"gut\" vermerkt, \n",
    "sodass wir auch hier herauslesen können, was ihr Skopus ist. \n",
    "\n",
    "Wir sind ja bisher so vorgegangen, dass negative Polarität durch negative Werte und positive Polarität durch positive Werte dargestellt werden. Wir berechnen die Polarität eines Satzes daher so, dass wir im Fall von Negationen den Polaritätswert des dazugehörigen Sentimentworts mit -1 multiplizieren und im Fall von verstärkenden Gradpartikeln mit 1,5.\n",
    "\n",
    "\n",
    "Satzpolarität = $\\sum_{i=1}^n KG x Pol(sw_i)$\n",
    "\n",
    "\n",
    "Dabei ist:\n",
    "- n: Zahl der Sentimentwörter im Satz\n",
    "- KG: Kontextgewicht (-1 für Negationen und 1,5 für verstärkende Gradpartikeln)\n",
    "- Pol(sw_i): Polaritätswert für das Sentimentwort, der im Sentimentwörterbuch steht\n",
    "\n",
    "\n",
    "Für unseren Satz \"Das Handy ist nicht gut\" haben wir das Sentimentwort \"gut\" mit einer Polarität von 0,7 und die Negation \"nicht\", sodass wir auf eine Polarität für den Satz von -0,7 kommen. Im Satz \"Das Handy ist sehr gut\" haben wir die Gradpartikel \"sehr\" und multiplizieren 0,7 mit 1,5, sodass wir auf einen Wert von 1,05 kommen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "Sobald Dokumente, die Meinungsäußerungen enthalten wie z. B. Rezensionen, komplexer werden als kurze Social-Media-Bemerkungen, muss die Analyse auf die Satzebene gehen und die Sätze eines Dokuments einzeln analysieren. Zunächst müssen dafür die Sätze identifiziert werden, der Text muss in Sätze unterteilt werden - die Satz-Tokenisierung. Nicht jeder Satz in einer komplexen Rezension enthält eine Bewertung. Daher werden die Sätze im nächsten Schritt als subjektive und objektive Sätze klassifiziert, häufig anhand von Schlüsselwörtern und Emojis, aber auch mit der Satzstruktur. Konditionalsätze und Fragesätze müssen gesondert behandelt werden. \n",
    "Bei der Analyse subjektiver Sätze sind Lösungen für Gradpartikeln und Negationen notwendig. Für die deutsche Sprache werden komplexere Lösungen notwendig als für die englische, vor allem wegen der möglichen Wortstellungsvariationen, denn vor allem Negationen können sowohl vor als auch hinter dem Wort stehen, das negiert wird.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weiterführende Literatur\n",
    "\n",
    "Umfassende Informationen zur Satz-Tokenisierungfinden Sie bei Heyer et al. (2006). Der skizzierte Ansatz für Negation, der für englischsprachige Sätze gut funktioniert, findet sich auf der Webseite von Christopher Potts: http://sentiment.christopherpotts.net/lingstruc.html#negation. In Pollard und Sag (1994) wird die HPSG-Analyse vorgestellt. Zu diesem Grammatikformalismus und seiner Umsetzung gibt es seitdem unzählige Publikationen. Die Webseite der internationalen Delph-In-Kooperation gibt hier weitere Hinweise: http://www.delph-in.net. Der Dependenz-Parser von spaCy wird hier beschrieben: https://spacy.io/usage/linguistic-features#dependency-parse. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übungen\n",
    "\n",
    "### Prüfen Sie Ihr Wissen\n",
    "\n",
    "- Worum geht es bei der Satz-Tokenisierung und was sind die Herausforderungen für die Arbeit mit der deutschen Sprache?\n",
    "- Welche Möglichkeiten gibt es, Sätze auf Subjektivität und Objektivität zu prüfen?\n",
    "- Was sind Gradpartikeln und Negation und wie beeinflussen sie die Sentiment-Analyse?\n",
    "\n",
    "### Setzen Sie Ihr neues Wissen ein\n",
    "\n",
    "Erweitern Sie Ihre Sentiment-Analyse so, dass ein Text zunächst in Sätze \n",
    "segmentiert wird. Die Polarität der Sätze wird dann einzeln ausgegeben \n",
    "und am Ende zusammengezählt. Dies ist eine mögliche Ausgabe der \n",
    "Software:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Grundsätzlich ist Sebastian Löbners Einführung in die Semantik empfehlenswert. POL: 1.0\n",
    "\n",
    "In 10 Kapiteln, die noch weiter unterteilt sind, werden die grundlegenden Aspekte der Semantik angerissen und vertieft. POL: 0.0\n",
    "\n",
    "Am Ende der Kapitel gibt es dann noch weiterführende bzw. erläuternde Literaturempfehlungen und Übungsaufgaben. POL: -0.3\n",
    "\n",
    "Löbner ist Professor für Sprachwissenschaft und das merkt man beim Lesen des Buches: POL: 0.0\n",
    "\n",
    "er weiß, wovon er spricht, das Thema wird gut vertieft, jedoch merkt man es auch an seiner oft umständlichen und komplizierten Sprache. POL: 0.3\n",
    "\n",
    "Da hilft es dann auch nicht mehr, dass das ganze Buch sehr übersichtlich gestaltet ist und man oft veranschaulichende Grafiken und Tabellen vorgesetzt bekommt. POL: 0.7\n",
    "\n",
    "Wenn der erläuternde Text dazu in verschachtelten Sätzen serviert wird und man sich das Ganze mehrere Male durchlesen muss, ist es trotzdem schwer zu verstehen. POL: -0.7\n",
    "\n",
    "Jedoch sind die Grafiken und Tabellen sehr gut und dienen sicherlich dazu, das Thema besser zu verstehen. POL: 3.25\n",
    "\n",
    "GESAMT: 4.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren Sie hier eine satzbasierte Sentiment-Analyse\n",
    "\n",
    "def sentiment_analysis_p(document):\n",
    "\n",
    "sentiment_analysis_p(loebner_document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erweitern Sie Ihre Sentiment-Analyse so, dass ein Satz zunächst als \n",
    "subjektiv oder objektiv klassifiziert wird, bevor die Polarität bestimmt \n",
    "wird.\n",
    "\n",
    "Verändern Sie Ihr Programm zur Sentiment-Analyse so, dass Negationen und Gradpartikeln beachtet werden:\n",
    "- Verändern Sie Ihr Programm zur Sentiment-Analyse so, dass beim Auftreten einer Negation die Polarität des nächsten Sentiment-Worts umgedreht wird.\n",
    "- Finden Sie eine Liste deutscher Negationen im Internet, die Sie verwenden können?\n",
    "- Fügen Sie dann noch Gradpartikeln wie  \"sehr\" oder \"total\" hinzu, die die Polarität erhöhen.\n",
    "- Testen Sie Ihr Programm mit dem GermEval-Korpus. Was funktioniert und was funktioniert nicht?\n",
    "\n",
    "Verändern Sie Ihr Programm so, dass eine Dependenzanalyse mit SpaCy \n",
    "durchgeführt wird und die Negation die Polarität seiner Head-Konstituente \n",
    "umdreht. Machen Sie dasselbe für Gradpartikeln, nur, dass diese die Polarität \n",
    "verstärken. Vergleichen Sie das Ergebnis mit dem Ergebnis der Negation ohne Grammatik aus der vorangehenden Übung auf dem GermEval-Korpus.\n",
    "\n",
    "### Reflexion in Gruppenarbeit\n",
    "\n",
    "Fügen Sie Sätze mit Negationen und Gradpartikeln in Ihren gemeinsamen Gold-Standard ein und prüfen Sie, ob Ihre Software diese richtig analysiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
