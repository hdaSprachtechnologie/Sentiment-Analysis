{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning mit Features\n",
    "\n",
    "Beim Supervised Learning auf Feature-Basis trainiert man ein Modell auf \n",
    "einer Liste von Merkmalen, die zuvor für den Text berechnet werden. So \n",
    "muss man zunächst entscheiden, welche Merkmale für das Training eines \n",
    "Modells interessant sein könnten, basierend auf der Zielsetzung des maschinellen Lernens. Hier ist ein Beispiel für ein Dokument im GermEval-Trainingskorpus:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<Document id=\"http://twitter.com/DOMKEYTV/statuses/733302306079379456\">\n",
    " <Opinions>            \n",
    "  <Opinion category=\"Zugfahrt#Pünktlichkeit\" \n",
    "     from=\"46\" to=\"55\" target=\"pünktlich\"\n",
    "    polarity=\"negative\"/>        \n",
    "  </Opinions>        \n",
    "  <relevance>true</relevance>        \n",
    "  <sentiment>negative</sentiment>        \n",
    "  <text>Waere ja mal ein Wunder wenn die deutsche  Bahn pünktlich faehrt</text>\n",
    "</Document>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir brauchen \"relevance\", um nur die relevanten Tweets für das \n",
    "Training auszuwählen. Den Wert in \"sentiment\" brauchen wir, weil er \n",
    "die Klassifikation enthält, die wir trainieren wollen. Den Text brauchen \n",
    "wir, weil wir daraus weitere Merkmale berechnen wollen. Ein solches \n",
    "Merkmal kann unser Wortlistenvergleich sein, der einen Polaritätswert \n",
    "als Ausgabe herausgibt. Weiterhin könnte die Anzahl der Negationen und \n",
    "Verstärker im Satz interessant sein. Der wichtigste Schritt ist, die Merkmale auszusuchen \n",
    "und dann zu berechnen. \n",
    "\n",
    "Hier ist eine Liste mit Negationen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations = ['NIE', 'nicht', 'nich', 'kein', 'keine', 'Keine', 'ohne', 'nie', 'nein', 'keiner', 'nichts', 'weder', 'Weder', 'garnicht', \n",
    "'statt', 'Nix', 'nix', 'wäre','Wäre', ':-)', 'Gegensatz', 'kaum', 'Niemand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist eine Liste mit Verstärkern:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verstaerker = ['sehr', 'total', 'enorm', 'häufig', 'wirklich', 'völlig','voellig', 'absolut', 'rein', 'endlich', 'vollstes', 'viel', 'hoffen', 'genug', 'Ziemlich', 'scharf', 'ziemlich', 'kolossalen', 'kolossale', 'kolossales', 'stark', 'hohes', 'hohe', 'zusätzlichen', \n",
    "'lupenreinen', 'absolut', 'schleichend', 'definitiv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dieser Definition lassen sich die Negationen und Verstärker in einem \n",
    "tokenisierten Satz zählen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_emp_in_sentence(sent):\n",
    "    negs = 0\n",
    "    emps = 0\n",
    "    for tok in sent:\n",
    "        if tok in negations:\n",
    "            negs = negs +1\n",
    "        elif tok in verstaerker:\n",
    "            emps = emps +1\n",
    "    return(negs, emps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Dokumente aus dem GermEval-Trainingskorpus im XML-Format werden nun so vorbereitet, \n",
    "dass sie im TSV-Format mit dem Polaritätswert aus unserem \n",
    "Wortlistenvergleich, der Anzahl an Negationen und Verstärkern und der \n",
    "Annotation als positiv, negativ oder neutral stehen. Die nicht \n",
    "relevanten Dokumente werden aussortiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "from wortlistenvergleich import *\n",
    "dev_data = open(r\"germeval_2017_dev.xml\",\"r\",encoding=\"utf-8\")\n",
    "out = open(\"out.txt\",\"w\",encoding=\"utf-8\")\n",
    "tree = ET.parse(dev_data)\n",
    "root = tree.getroot()\n",
    "\n",
    "def convert_data():\n",
    "    for document in root.iter('Document'):\n",
    "        relevance = document.find('relevance').text\n",
    "        sent = document.find('text').text\n",
    "        sentiment = document.find('sentiment').text\n",
    "        polarity = sentiment_analysis(sent)\n",
    "        (negs, emps) = neg_emp_in_sentence(sent)\n",
    "        if relevance == 'true':\n",
    "            out.write(str(sent) + '\\t' + str(polarity)\n",
    "             + '\\t' + str(negs) + '\\t' + str(emps) + '\\t' \n",
    "             + str(sentiment) + '\\n')\n",
    "    dev_data.close()\n",
    "    out.close()\n",
    "    \n",
    "convert_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Beispiel für eine Umwandlung in das neue Format ist:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<Document id=\"http://twitter.com/Ariantoser/statuses/\n",
    "   687328181582475265\">\n",
    "  <Opinions>\n",
    "   <Opinion category=Allgemein\\# Haupt\" from=\"81\" to=\"101\"\n",
    "    target=\" ueber die Bahn aergern\" polarity=\"negative\"/>\n",
    "  </Opinions>\n",
    "  <relevance>true</relevance>\n",
    "  <sentiment>negative</sentiment>\n",
    "  <text>RT @Tryli: Wie schoen es ist wenn man \n",
    "   sich nach nem nervigen Arbeitstag auch noch \n",
    "   ueber die Bahn aergern muss.</text>\n",
    "</Document>\n",
    "\n",
    "RT @Tryli: Wie schön es ist wenn man sich nach nem nervigen Arbeitstag auch noch über die Bahn ärgern muss.\t-1.0\t0\t0\tnegative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir benennen die Datei um in germeval_trainingdata.txt.\n",
    "\n",
    "Mit den so vorbereiteten Texten können wir jetzt ein Modell trainieren. \n",
    "Das hier vorgestellte Vorgehen orientiert sich an Jason Brownlee (https://machinelearningmastery.com/machine-learning-in-python-step-by-step/). \n",
    "\n",
    "Wir müssen einige Python-Module importieren, bevor wir beginnen: Pandas (https://pandas.pydata.org/about/) ist eine Bibliothek mit Werkzeugen für den Umgang mit Daten. Scikit-learn (https://scikit-learn.org/stable/), das wir als \"sklearn\" importieren, stellt Werkzeuge für das maschinelle Lernen bereit. Pickle (https://docs.python.org/3/library/pickle.html) benötigen wir, um das gelernte Modell abzuspeichern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst lokalisieren wir die vorbereitete Eingabedatei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = (r\"germeval_trainingdata.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann verweisen wir auf die Bedeutung der Spalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['text', 'polarity', 'neg', 'emp', 'cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier lesen wir jetzt die Datei mit ihren Spalten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(input_data, sep='\\t', names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt \"erklären\" wir die Features in der Datei: Die \n",
    "erste Spalte ist der Text (den wir ignorieren), danach kommen drei \n",
    "Zahlenwerte, die für die Berechnung genutzt werden, in der letzten \n",
    "Spalte steht die Kategorie, die wir klassifizieren wollen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "\n",
    "X = array[:,1:4]\n",
    "\n",
    "X = X.astype('int')\n",
    "\n",
    "Y = array[:,4]\n",
    "\n",
    "Y = Y.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann teilen wir den Korpus in 80% Trainings- und 20% Testdaten \n",
    "zufällig auf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt verschiedene Klassifikatoren, die man jetzt ausprobieren könnte. \n",
    "Wir entscheiden uns der Einfachheit halber für einen, den Decision Tree Classifier, und \n",
    "trainieren unser Modell damit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    model_file = 'finalized_model.sav'\n",
    "    pickle.dump(classifier, open(model_file, 'wb'))\n",
    "    \n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell ist nun in einer Datei mit dem Namen 'finalized_model.sav' \n",
    "gespeichert und wir können es anwenden. Wenn wir es auf einen Text \n",
    "anwenden wollen, dann müssen wir diesem Text dieselben Werte zuweisen \n",
    "wie den Trainingstexten, also Polarität nach Wortlistenvergleich, Anzahl \n",
    "der Negationen und Anzahl der Verstärker. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_senti_sentence(sent):\n",
    "    (neg, emp) = neg_emp_in_sentence(sent)\n",
    "    polarity = sentiment_analysis(sent)\n",
    "    sent_array = [[polarity,neg,emp]]\n",
    "    model = pickle.load(open('finalized_model.sav', 'rb'))\n",
    "    result = model.predict(sent_array)[0]\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt kann man Texte prüfen und ein Gefühl dafür bekommen, wie gut das \n",
    "Modell ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_senti_sentence(\"Wir leiden unter Bahnlärm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pred_senti_sentence(\"Meine Strecke war stundenlang gesperrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_senti_sentence(\"Bei der Bahn ist WLAN kostenlos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Qualität der Klassifikation hängt einerseits von der Qualität der Merkmale \n",
    " und andererseits von der Größe und der Ausgewogenheit des \n",
    "Trainingskorpus ab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den Daten der GermEval stellen wir  fest, dass die Klassifikation von positiven Texten nicht gelingt. Egal, wie das Modell trainiert ist, kein Satz wird als positiv klassifiziert.\n",
    "Ein näherer Blick in die Daten zeigt, warum das so ist: 590 negative und 1199 neutrale Texte stehen lediglich 151 positiven gegenüber. Wir haben also einen nicht ausgewogenen Datensatz. Die Gesamt-Accuracy ist damit einfach am höchsten, wenn das Modell annimmt, dass es keine positiven Meinungsäußerungen im Datensatz gibt.\n",
    "Wenn man nun mit einem ausgewogenen Datensatz trainiert, also mit je ca. 150 negativen, neutralen und positiven Texten, dann gelingt auch die Klassifikation mit dem trainierten Modell. Allerdings ist der Datensatz dann letztlich zu klein, um ein wirklich gutes Modell trainieren zu können. Man könnte sich auch vorstellen, die 151 positiven Texte im Datensatz zu erweitern, indem man sie kopiert und leicht modifiziert, also Varianten davon erzeugt. Das Problem des maschinellen Lernens auf nicht ausgewogenen Datensätzen und verschiedene Methoden, damit umzugehen, werden  bei Haixiang et al. (2017) beschrieben. \n",
    "\n",
    "Forschungsgruppen haben mit weiteren Merkmalen experimentiert, wie der Zahl der Sentiment-Wörter im Text, dem maximalen Polaritätswert im Text, den negativen und den positiven Polaritätswerten, dem Polaritätswert des letzten Sentiment-Wortes im Satz oder den Tf-idf-Werten für alle Wörter im Text. \n",
    "\n",
    "(Beim Tf-idf-Maß handelt es sich um ein Maß aus dem Information Retrieval, bei dem die Häufigkeit des Auftretens eines Wortes in einem Dokument mit der Häufigkeit des Auftretens in der gesamten Dokumentmenge in  Beziehung gesetzt wird. Für nähere Informationen dazu siehe Ferber (2003).)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
