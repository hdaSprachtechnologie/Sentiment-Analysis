{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Was bewertet wird: Aspekte identifizieren\n",
    "\n",
    "In einigen Anwendungen reicht es nicht aus zu wissen, ob ein Dokument \n",
    "oder ein Satz eine positive oder negative Meinungsäußerung enthält. Wenn \n",
    "man sich z. B. die Meinungsäußerungen zur Deutschen Bahn aus der GermEval 2017 ansieht, dann werden unterschiedliche Aspekte der Bahn bewertet, \n",
    "wie Pünktlichkeit, Sauberkeit, Freundlichkeit des Personals usw. Es ist gut vorstellbar, dass das Management der Bahn nicht nur wissen möchte, wie die Bahn insgesamt von ihren Kunden bewertet wird, sondern auch, welche Aspekte schon sehr gut ankommen und welche noch verbessert werden müssen. Die  \"Subtask C\" der GermEval 2017 wird daher so beschrieben (übersetzt von: https://sites.google.com/view/germeval2017-absa/home):\n",
    "\n",
    "***\n",
    "### Subtask C) Polarität auf Aspekt-Ebene\n",
    "\n",
    "Identifizieren Sie alle Aspekte, die im Rahmen der Rezension positiv und negativ bewertet werden. Um die Vergleichbarkeit zu erhöhen, werden die Aspekte vorher in Kategorien eingeteilt (siehe Daten). Ziel der Teilaufgaben ist es daher, alle enthaltenen Kategorien und die damit verbundene Polarität zu identifizieren.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "*alle so  \"Yeah, Streik beendet\" Bahn so  \"okay, dafür werden dann \n",
    "natürlich die Tickets teurer\" Alle so  \"Können wir wieder Streik \n",
    "haben?\" relevant neutral Ticketkauf#Haupt:negativ Allgemein# Haupt:positiv*\n",
    "\n",
    "\n",
    "In diesem Post besteht die Aufgabe darin, die Aspekte (und ihre Polarität) zu identifizieren: Ticketkauf# Haupt:negativ Allgemein# Haupt:positiv \n",
    "\n",
    "***\n",
    "\n",
    "In einem Satz können mehrere Aspekte einer Domäne unterschiedlich \n",
    "bewertet werden. Schauen wir z. B. noch mal in unsere Buch-Rezension aus dem Kapitel 5:\n",
    "\n",
    "*er weiß, wovon er spricht, das Thema wird gut vertieft, jedoch merkt man \n",
    "es auch an seiner oft umständlichen und komplizierten Sprache.*\n",
    "\n",
    "In einem Satz werden gegensätzliche Meinungen (positiv und negativ) zu \n",
    "unterschiedlichen Aspekten (Vertiefung, Sprache) des Buches geäußert. \n",
    "\n",
    "Aufgabe der aspektbasierten Sentiment-Analyse ist also, Aspekte zu identifizieren, über die eine Meinung geäußert \n",
    "wird, die Meinungsäußerungen zu identifizieren und zu klassifizieren und \n",
    "beides miteinander zu verknüpfen.\n",
    "Der nächste Abschnitt beschäftigt sich mit einer Taxonomie der Aspekte in einer Domäne. Anschließend sehen wir uns die sprachlichen Formen an, mit denen diese Aspekte realisiert werden können. Danach geht es darum, wie diese Aspekte im Text gefunden und interpretiert werden  und schließlich um die Sentiment-Klassifikation der Aspekte. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomie der Aspekte\n",
    "\n",
    "Wenn die aspektbasierte Sentiment-Analyse auf eine Domäne beschränkt ist, dann wird zunächst ein Datenmodell der \n",
    "Domäne mit ihren Entitäten und Aspekten aufgebaut. In einer Shared Task \n",
    "wie GermEval 2017 ist das geschehen, bevor die Texte annotiert worden \n",
    "sind. Dort gibt es zum Beispiel die Entität \n",
    " \"Service/Kundenbetreuung\" mit den Aspekten  \"Zugbetreuung\", \n",
    " \"Am-Platz-Service/1. Klasse-Service\" und  \"Sonstiges\". Die erste \n",
    "Aufgabe der Aspektklassifikation ist also die Aufstellung einer \n",
    "Taxonomie der Entitäten und Aspekte, deren Bewertungen analysiert werden \n",
    "sollen. In den meisten Fällen wird dies manuell und abhängig von der Zielsetzung der Analyse gemacht, denn die \n",
    "Aspekte, die für einen Nutzer interessant sind, sind für einen anderen \n",
    "Nutzer einer Sentiment-Analyse eventuell uninteressant. Außerdem gehören \n",
    "zur Domäne  \"Bahn\" andere Aspekte als beispielsweise zur Domäne \n",
    " \"Fahrrad\". Der Prozess des Taxonomie-Aufbaus kann durch eine \n",
    "automatische Terminologie-Extraktion unterstützt werden, wie er in \n",
    "(Siegel und Drewer 2012) skizziert ist. Aus der Liste der \n",
    "Terminologie, die in den Texten verwendet wird, lässt sich eine \n",
    "Taxonomie extrahieren. Eine Ressource wie OdeNet\n",
    "(Siegel 2020) kann Hinweise für die hierarchische \n",
    "Strukturierung geben. Eine andere Möglichkeit ist, die Meinungsausdrücke \n",
    "in den Texten zu identifizieren und die Ziele dieser Ausdrücke in die \n",
    "Aspekt-Taxonomie aufzunehmen.\n",
    "\n",
    "Die Taxonomie der GermEval 2017 ist die folgende:\n",
    "\n",
    "- Allgemein\n",
    "- Atmosphäre\n",
    "    - Lautstärke\n",
    "    - Beleuchtung\n",
    "    - Fahrgefühl\n",
    "    - Temperatur\n",
    "    - Sauberkeit allgemein\n",
    "    - Geruch\n",
    "    - Sonstiges\n",
    "    - Connectivity\n",
    "    - WLAN/Internet\n",
    "    - Telefonie/Handyempfang\n",
    "    - ICE Portal\n",
    "    - Sonstiges\n",
    "- Design\n",
    "- Gastronomisches Angebot\n",
    "    - Verfügbarkeit Bordbistro/- restaurant\n",
    "    - Verfügbarkeit angebotener Produkte\n",
    "    - Vielfalt/Auswahl\n",
    "    - Preise\n",
    "    - Gastronomiebetreuung\n",
    "    - Sonstiges\n",
    "- Informationen\n",
    "- DB App und Website\n",
    "    - Informationen DB App und Website\n",
    "    - Störungen DB App und Website\n",
    "- Service/Kundenbetreuung\n",
    "    - Zugbetreuung \n",
    "    - Am-Platz-Service/1. Klasse- Service\n",
    "    - Sonstiges\n",
    "- Komfort/Ausstattung\n",
    "    - Sitzkomfort\n",
    "    - Funktionsfähigkeit Sitz und Sitzverstellbarkeit\n",
    "    - Reservierung\n",
    "    - Steckdosen\n",
    "    - Kleiderhaken\n",
    "    - Sauberkeit Sitzplatz\n",
    "    - Sonstiges\n",
    "- Gepäck \n",
    "- Auslastung und Platzangebot\n",
    "- Ticketkauf\n",
    "- Toiletten\n",
    "    - Funktionsfähigkeit Toiletten\n",
    "    - Sauberkeit Toilette\n",
    "    - Geruch Toilette\n",
    "    - Verfügbarkeit Verbrauchsmaterial\n",
    "    - Sonstiges\n",
    "- Zugfahrt\n",
    "    - Pünktlichkeit\n",
    "    - Anschlusserreichung\n",
    "    - Technische Schäden / Störungen am Zug\n",
    "    - Wagenreihung\n",
    "    - Fahrtzeit / Schnelligkeit \n",
    "    - Streckennetz\n",
    "    - Sonstige Unregelmäßigkeiten\n",
    "- Reisen mit Kindern\n",
    "- Image\n",
    "    - Sponsoring\n",
    "    - Marketing\n",
    "- QR-Code\n",
    "- Barrierefreiheit\n",
    "- Sicherheit\n",
    "\n",
    "Nicht alle Aspekte der Taxonomie sind jedoch in den Entwicklungsdaten \n",
    "annotiert. Z. B. gibt es keine Beispiele für Aussagen zum Aspekt \"Gastronomiebetreuung\".\n",
    "\n",
    "Bei der Arbeit mit annotierten Daten kann die Aspekt-Taxonomie aus der \n",
    "Annotation übernommen werden. In den GermEval-2017-Daten stehen diese im XML-Tag \n",
    "\"category\":\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "       <Opinions>\n",
    "            <Opinion category=\"Sonstige_Unregelmässigkeiten\\# Haupt\"\n",
    "               from=\"80\" to=\"88\" target=\"entfällt\" polarity=\"negative\"/>\n",
    "        </Opinions>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrasen-Lexikon der Aspekte}\n",
    "\n",
    "Im nächsten Schritt müssen Phrasen aus dem Text Aspekten dieser \n",
    "Taxonomie zugeordnet werden, um ein Lexikon der Aspekte und der \n",
    "dazugehörigen Phrasen aufzustellen. Wenn die Textphrasen als \n",
    "\"Targets\" in den Trainingsdaten annotiert sind wie bei GermEval \n",
    "2017, können diese direkt extrahiert werden. Hier ist ein Beispiel, mit dem Target \"Störung\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    <Document id=\"http://twitter.com/LaVieVagabonde/statuses/670623192583708672\">\n",
    "        <Opinions>\n",
    "            <Opinion category=\"Sonstige_Unregelmässigkeiten#Haupt\" from=\"41\" to=\"48\"\n",
    "                           target=\"Störung\" polarity=\"negative\"/>\n",
    "        </Opinions>\n",
    "        <relevance>true</relevance>\n",
    "        <sentiment>negative</sentiment>\n",
    "        <text>@RMVdialog hey, wann fährt denn nach der Störung jetzt die nächste\n",
    "                  Bahn von Glauberg nach Ffm?</text>\n",
    "    </Document>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Möglichkeit, die \n",
    "Phrasenlisten zu erweitern, besteht darin, Synonyme der extrahierten \n",
    "Phrasen hinzuzufügen. Diese Synonyme bekommt man aus Synonymlisten, \n",
    "Synonymwörterbüchern wie openthesaurus.de (https://www.openthesaurus.de/) oder WordNets wie OdeNet \n",
    "(Siegel 2020). Bei einer Erweiterung der Liste mit \n",
    "OdeNet, das auf dem openthesaurus.de beruht, bekommt man z. B. für das Wort \n",
    " \"Abzocke\" im Aspekt \"Allgemein# Haupt\" diese Synonymliste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Abzocke', 'Abzockerei', 'Bauernfängerei', 'Beschmu', 'Betrug', \n",
    "'Beutelschneiderei', 'Fraud', 'Gaunerei', 'Geldmacherei', \n",
    "'Geldschneiderei', 'Manipulation', 'Nepp', 'Profitmacherei', \n",
    "'Rosstäuscherei', 'Schmu', 'Schummelei', 'Schwindel', 'Trickserei', \n",
    "'Täuschung', 'Wucher', 'krumme Tour']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus diesem Beispiel ist schnell ersichtlich, wie sinnvoll eine \n",
    "Erweiterung mit Synonymen sein kann. Allerdings können Probleme \n",
    "auftreten, die darauf beruhen, dass Synonyme in unterschiedlichen \n",
    "Kontexten zu finden sind: Ebenfalls für den Aspekt \n",
    " \"Allgemein\\# Haupt\" ist \"Bau\" annotiert. Eine Suche nach \n",
    "Synonymen dafür ergibt Folgendes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Aushöhlung', 'Bau', 'Bauwerk', 'Bunker', 'Errichtung', 'Gebäude', \n",
    "'Gefängnis', 'Gemäuer', 'Haftanstalt', 'Hafthaus', 'Haftort', \n",
    "'Hohlraum', 'Häfen', 'Höhle', 'Höhlung', 'JVA', 'Justizvollzugsanstalt', \n",
    "'Kahn', 'Kerker', 'Kiste', 'Kittchen', 'Knast', 'Konstruktion', 'Loch', \n",
    "'Strafanstalt', 'Strafvollzugsanstalt', 'Vollzugsanstalt', 'Zuchthaus', \n",
    "'schwedische Gardinen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sicher ist im Kontext der Bahn das Auftreten des Nomens \"Knast\" sehr \n",
    "selten und nicht ein Hinweis auf den gemeinten Aspekt. Bei einer \n",
    "automatischen Erweiterung der möglichen Targets sollte daher immer \n",
    "manuell nachbearbeitet werden.\n",
    "\n",
    "Wenn in den Trainingsdaten die Targets nicht markiert sind, gibt es die \n",
    "Möglichkeit, mit dem Wortschatz zu arbeiten. Man nimmt dann alle Wörter, \n",
    "die in Sätzen vorkommen, die mit einem Aspekt annotiert sind, und \n",
    "vergleicht sie mit den Wörtern aller anderen Sätzen. Dies ist dasselbe \n",
    "Verfahren wie bei der Gewinnung von Sentiment-Wörtern aus annotierten Korpora (Kapitel 4).\n",
    "\n",
    "Sehen wir uns zum Beispiel die Wortliste für den Aspekt \n",
    " \"Atmosphäre# Geruch\" an:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['10', '35', '?', 'Alkoholdunst', 'Alle', 'Alleine', 'Arbeit', \n",
    "'Arschloch', 'Bahn', 'Bahnhof', 'BauerJaM', 'Berlin', 'Bett', 'Bild', \n",
    "'Damit', 'Das', 'Der', 'Dermassen', 'Die', 'Diese', 'Es', 'Fürze', \n",
    "'Genau', 'Grad', 'Hannover', 'Haus', 'Herunter', 'Hier', 'Immer', 'In', \n",
    "'Irgendwo', 'Jetzt', 'Klo', 'Knoblauch', 'Koeln', 'Kommen', 'Leute', \n",
    "'Lust', 'Man', 'Mann', 'Max', 'Mehr', 'Millionenhöhe', 'Mischung', \n",
    "'Mit', 'Modernste', 'Monat', 'Nach', 'Neben', 'Nehmen', 'Nicht', \n",
    "'Nichts', 'Noch', 'Nun', 'Ob', 'Pommes', 'Pommesflusterer', 'Punkt', \n",
    "'Raucherabteile', 'Raus', 'Rt', 'S', 'S-Bahn', 'Sitzplätze', 'Slums', \n",
    "'Sowieso', 'Spruch', 'Stadt', 'Station', 'Stinkepenner', 'Tiket', \n",
    "'Tourist', 'UBahnen', 'Unbeschadet', 'Und', 'Verbrecher', 'Warum', \n",
    "'Weiss', 'Wenn', 'Zeit', 'Zigarettenrauch', 'Zu', 'Zug', 'Zur', 'alle', \n",
    "'ander', 'auf', 'aus', 'außen', 'bei', 'besetzen', 'bewerten', \n",
    "'bezahlen', 'bleiben', 'cologneisnotberlin', 'das', 'dass', 'dazu', \n",
    "'den', 'der', 'diesen', 'doch', 'du', 'dumm', 'eigentlich', 'ein', \n",
    "'einen', 'einpferchen', 'erst', 'ertragen', 'es', 'finally', 'fordern', \n",
    "'fragen', 'ganz', 'geben', 'grad', 'haben', 'hier', 'ich', 'ihre', \n",
    "'ihren', 'im', 'in', 'kein', 'kommen', 'kotzen', 'können', 'letzt', \n",
    "'löffeln', 'malen', 'man', 'mehr', 'me\\ldots ', 'mir', 'mit', 'müssen', \n",
    "'nach', 'nicht', 'nur', 'oe24.at', 'persönlich', 'pissen', 'renovieren', \n",
    "'riechen', 'scheißen', 'schlimm', 'schön', 'sehen', 'sein', 'selbe', \n",
    "'sich', 'sollen', 'sparen', 'stinken', 'stinkend', 'und', 'verreisen', \n",
    "'versumpfen', 'viel', 'welch', 'werden', 'wie', 'win', 'wissen', 'wo', \n",
    "'zu', 'zum', 'überfüllt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wörter, die nur in Sätzen zu diesem Aspekt und nicht in Sätzen zu \n",
    "anderen Aspekten vorkommen, sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Mischung', 'Pommesflusterer', 'Klo', 'finally', 'pissen', 'stinken', \n",
    "'win', 'cologneisnotberlin', 'Dermassen', 'Stinkepenner', \n",
    "'Raucherabteile', 'Zigarettenrauch', 'Pommes', 'me... ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Qualität der mit dieser Methode gewonnenen Wortlisten ist stark \n",
    "abhängig davon, wie viele annotierte Texte verfügbar sind. Manuelle \n",
    "Nachbearbeitung ist auch hier notwendig. \n",
    "\n",
    "Eine weitere Möglichkeit, das Lexikon der Phrasen für Aspekte zu erweitern, ist die Nutzung von Word Embeddings, wie im Kapitel 4 beschrieben. Mit dieser Methode ist es möglich, Wörter in einem sehr großen Textkorpus zu finden, die den bereits gefundenen semantisch ähnlich sind. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aspekte im Text identifizieren und interpretieren\n",
    "\n",
    "Mit dem Phrasenlexikon können jetzt Aspekte im Text identifiziert \n",
    "werden. Wenn im Text z. B. das Wort  \"Zigarettenrauch\" auftritt, kann \n",
    "mit der Liste der Targets und Aspekte herausgefunden werden, dass es um \n",
    "den Aspekt  \"Atmosphäre# Geruch\" geht. Problematischer als dieses \n",
    "Beispiel sind die Mehrwortlexeme. In der Liste der Targets steht z. B. \n",
    " \"über die Bahn ärgern\" als Target für den Aspekt \n",
    " \"Allgemein# Haupt\". Im Text steht das auch in derselben Form:\n",
    "\n",
    "*RT @Tryli: Wie schön es ist wenn man sich nach nem nervigen Arbeitstag \n",
    "auch noch über die Bahn ärgern muss.*\n",
    "\n",
    "\n",
    "Was aber, wenn jemand schreibt:  \"Ich ärgere mich über die Bahn\" oder \n",
    " \"über die Bahn muss ich mich immer ärgern\"? In diesem Fall sollte \n",
    "man vielleicht das Target auf  \"Bahn\" reduzieren und  \"ärgern\"\n",
    "(mit allen flektierten Formen) als Sentiment-Wort aufnehmen. Ein anderes \n",
    "Target aus der Liste ist  \"Ticket * online buchen\" für den Aspekt \n",
    " \"Ticketkauf# Haupt\". Der dazu passende Text, bei dem die automatische Erkennung der Polarität durch die enthaltene Ironie besonders komplex ist:\n",
    "\n",
    "*RT @pinokju: In 231 einfachen Schritten ein Ticket der Deutschen Bahn \n",
    "online buchen.*\n",
    "\n",
    "Dabei steht das Sternchen (\\*) für ein oder mehrere Wörter. Hier würde \n",
    "man vielleicht auch reduzieren auf  \"online buchen\" und alle \n",
    "Online-Buchungen im Kontext der Bahn auf den Aspekt \n",
    " \"Ticketkauf# Haupt\" abbilden, auch wenn z. B. ein Sitzplatz gebucht \n",
    "wird. \n",
    "\n",
    "Ein weiteres Problem sind Anaphern. Wenn ein Aspekt in einem Folgesatz \n",
    "wiederaufgenommen und dann erst bewertet wird, kann das mit einem \n",
    "Pronomen geschehen, wie in diesem Beispiel:\n",
    "\n",
    "*Die Bahn wird schneller...Wenn \\underline{Sie} mal kommt!*\n",
    "\n",
    "Eine Methode dafür ist, den Aspekt aus dem vorangehenden Satz so lange \n",
    "beizubehalten, bis ein neuer Aspekt explizit genannt wird. In Sukthanker et al. (2018) werden weitere Methoden der Anaphern-Auflösung beschrieben.\n",
    "\n",
    "Nicht alle Aspekte sind explizit mit eindeutigen Target-Wörtern \n",
    "identifizierbar. Im modellierten und recht eingeschränkten Kontext wie \n",
    "der Bahn ist das Target-Wort  \"teuer\" immer ein Hinweis auf den \n",
    "Aspekt  \"Ticketkauf# Haupt\". Das könnte aber in anderen Kontexten \n",
    "anders sein: Nehmen wir als Beispiel die Domäne  \"Autokauf\". Dort \n",
    "kann natürlich das Auto teuer sein, aber auch die Extras, die Wartung \n",
    "oder die Garantieverlängerung.  \"Teuer\" steht für den impliziten \n",
    "Aspekt \"Preis\".\n",
    "\n",
    "Noch schwieriger wird es, wenn der Aspekt umschrieben ist, wie in diesem \n",
    "Beispiel zum Aspekt \"Atmosphäre# Temperatur\":\n",
    "\n",
    "*@JensK1002 @DB\\_Bahn mußten sie für den Sauna-Besuch zuzahlen ???*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspektidentifizierung ohne Beschränkung auf eine Domäne\n",
    "\n",
    "Bisher sind wir davon ausgegangen, dass wir die Domäne - das Themengebiet - genau kennen, in dem Aspekte bewertet werden. Nun könnte man sich vorstellen, dass eine aspektbasierte Sentiment-Analyse für unterschiedliche Domänen implementiert werden soll oder dass nicht genügend Zeit ist, um eine Taxonomie der Aspekte aufzubauen. \n",
    "Hier kommt die klassische Terminologie-Extraktion ins Spiel: Die \"Fachwörter\" werden aus dem Text als mögliche (explizite) Aspekte extrahiert. Dafür stehen grundsätzlich drei Methoden zur Verfügung, die auch kombiniert werden können: Die erste Möglichkeit ist, alle Wörter, die mit Großbuchstaben beginnen oder die aus Großbuchstaben bestehen, zu extrahieren. Diese Methode, die natürlich nur für die deutsche, nicht aber für die englische Sprache funktioniert, erkennt vor allem Nomen und Namen. Die zweite Möglichkeit ist, alle Wörter zu extrahieren, die nicht zu den am häufigsten gebrauchten Wörtern der Sprache gehören. Hier ist z. B. ein Vergleich mit den 1.000 häufigsten Wörtern des Deutschen, die durch den \"Wortschatz Leipzig\" zur Verfügung gestellt werden (https://wortschatz.uni-leipzig.de/de), möglich. Die dritte Möglichkeit ist schließlich die Aufstellung von Pattern-Regeln, mit denen z. B. Ketten von Nomen oder auch Adjektive mit dahinterstehenden Nomen extrahiert werden. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment-Klassifikation des Aspekts\n",
    " \n",
    "Da wir nun in der Lage sind, Sentiment-Ausdrücke im Text zu \n",
    "klassifizieren und Aspekte zu erkennen, gilt es, beides zusammen zu \n",
    "bringen. Die einfachste Methode dafür ist, beides im Satz zu finden und \n",
    "dann eine Verbindung anzunehmen. Wenn der Satz nur einen Aspekt-Ausdruck \n",
    "und einen Sentiment-Ausdruck enthält, ist das eine sinnvolle Methode. So \n",
    "erkennt die Aspekt-Klassifikation den Aspekt \"Zugfahrt# Haupt\" und \n",
    "die Sentiment-Klassifikation ein positives Sentiment in diesem \n",
    "Satz aus den GermEval-Daten:\n",
    "\n",
    "\n",
    "*@flyingdutchy04 und selbst wenn, würde ich eine reise mit der db \n",
    "vorziehen,*\n",
    "\n",
    "In den GermEval-Entwicklungsdaten gibt es nur wenige Fälle, in denen in \n",
    "einem Text Meinungen zu mehreren Aspekten geäußert werden. Die Polarität \n",
    "wechselt meist dabei über den Text nicht. Hier ist ein Beispiel dafür:\n",
    "\n",
    "\n",
    "*@DB\\_Bahn Wagen 21 fehlt. Reservierungen sind aufgehoben. Zug ist sehr \n",
    "voll.*\n",
    "\n",
    "\n",
    "Für dieses Beispiel ist es nicht unbedingt notwendig, die Satzgrenzen in \n",
    "die Analyse einzubeziehen, weil die Polarität in allen drei Sätzen \n",
    "negativ ist. Man nimmt also dieselbe Polarität für alle Aspekte im Dokument gleichermaßen an, ein Ansatz, den \\cite{Hu:Liu:2004} verfolgen.\n",
    "\n",
    "Ein Beispiel für gegensätzliche Meinungen zu unterschiedlichen Aspekten \n",
    "ist das folgende:\n",
    "\n",
    "\n",
    "*Heute mal mit der @DB\\_Bahn zur Arbeit. Deutlich entspannter, aber \n",
    "doppelt so lange unterwegs*\n",
    "\n",
    "Der Aspekt  \"Zugfahrt# Haupt\" wird positiv, der Aspekt \n",
    " \"Zugfahrt# Fahrtzeit_und_Schnelligkeit\" negativ bewertet. Dazu \n",
    "kommt, dass beide Bewertungen im zweiten Satz stehen, der Aspekt \n",
    " \"Zugfahrt# Haupt\" aber im ersten Satz. Der Schlüssel dazu ist das \n",
    "Wort  \"aber\". Ein ähnliches Beispiel:\n",
    "\n",
    "*@lokfuehrer\\_tim Schönen Feierabend! Ich bin heute zwar langsam, aber \n",
    "pünktlich ca. 225 km Bahn in 4 Stunden gefahren ...*\n",
    "\n",
    "\n",
    "Hier werden der Aspekt  \"Zugfahrt#Fahrtzeit_und_Schnelligkeit\" \n",
    "negativ und der Aspekt  \"Zugfahrt#Pünktlichkeit\" positiv bewertet. Eine \n",
    "sinnvolle Vorgehensweise ist, im Fall von Wörtern wie  \"aber\", \n",
    " \"trotzdem\" oder \"jedoch\" den Text in zwei Teile zu teilen und \n",
    "diese getrennt zu kategorisieren.\n",
    "\n",
    "Nicht immer sind Sentiment und Aspekt durch unterschiedliche Wörter oder \n",
    "Phrasen im Satz markiert. So gibt es Aspekte, die immer negativ sind, \n",
    "wie  \"Sonstige_Unregelmässigkeiten#Haupt\" oder \n",
    " \"Zugfahrt#Sonstige_Unregelmässigkeiten\". Diese Aspekte können als \n",
    "negativ markiert werden, ohne dass eine weitere Sentiment-Analyse \n",
    "notwendig ist. \n",
    "\n",
    "Andererseits gibt es Sentiment-Wörter, die auch gleichzeitig implizite \n",
    "Aspekte bezeichnen, wie z. B. das Verb \"stinkt\" (negativ, \n",
    "Atmosphäre#Geruch) oder auch das Verb  \"teuer\" (negativ, \n",
    "Ticketkauf#Haupt). Diese Wörter müssen in das Sentiment-Lexikon und das \n",
    "Aspekt-Lexikon aufgenommen werden.\n",
    "\n",
    "Eine andere Möglichkeit, Sentiment-Ausdruck und Aspekt-Ausdruck in eine \n",
    "Beziehung zu setzen, ist die Nutzung eines Dependenzparsers. Dieser \n",
    "analysiert die Satzsyntax und stellt die Wörter im Satz in eine \n",
    "Beziehung. Dieses Verfahren kann für Social-Media-Daten problematisch \n",
    "sein, denn diese sind oft nicht standardsprachlich formuliert, sodass \n",
    "die Dependenzanalyse keine guten Ergebnisse liefert. Wenn man aber z. B. \n",
    "Zeitungstexte oder Buchrezensionen analysiert, kann das Verfahren genauere Ergebnisse liefern \n",
    "als das oben beschriebene Verfahren. \n",
    "\n",
    "Die Dependenzanalyse von spaCy liefert für den einfachen Satz \"Das ist \n",
    "die doofe Bahn\" folgendes Ergebnis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc = nlp(\"Das ist die doofe Bahn\")\n",
    "for token in doc:\n",
    "    print(token.lemma_,token.pos_,token.dep_,token.head.text,token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Dependenzbaum lässt sich auch visualisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jedes Wort haben wir hier das Lemma, die syntaktische Kategorie, die \n",
    "Art der Dependenz, das Kopfwort in der Dependenzbeziehung und das Wort \n",
    "selbst. Das bewertende Adjektiv  \"doofe\" hat als Kopfwort \"Bahn\", \n",
    "woraus man schließen kann, dass hier die Bahn bewertet wird. Wir müssen \n",
    "also eine Dependenzanalyse durchführen, dann die bewertenden Wörter \n",
    "identifizieren und schauen, ob sie als Kopfwort ein Wort haben, das in \n",
    "der Liste der Targets steht. Wenn das der Fall ist, dann wird der \n",
    "dazugehörige Aspekt mit seiner Bewertung ausgegeben. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "Mehrere Aspekte einer Domäne können in einer Rezension - oft sogar in einem Satz - unterschiedlich bewertet werden. Die aspektbasierte Sentiment-Analyse versucht, Aspekte zu identifizieren, Meinungsäußerungen zu klassifizieren und dann beides miteinander zu verknüpfen. \n",
    "Um Aspekte zu identifizieren, wird im ersten Schritt eine Taxonomie der Entitäten und Aspekte der Domäne aufgestellt. Für diese Aspekte werden dann sprachliche Ausdrücke gesucht, die man einerseits in den Entwicklungsdaten und andererseits in externen Quellen wie Synonymlexika finden kann. Die so aufgestellten und klassifizierten Wort- und Phrasenlisten werden anschließend im zu analysierenden Text gesucht. Bei Phrasen ist das insbesondere im Deutschen alles andere als trivial. Schließlich müssen Aspekte und Sentiment zusammengeführt werden. Dabei ist es notwendig, auch Wörter wie  \"aber\" oder \"jedoch\" in die Analyse einzubeziehen. \n",
    "Viele Systeme, die auf wissenschaftlichen Konferenzen vorgestellt werden, identifizieren mit Verfahren des maschinellen Lernens auf annotierten Trainingsdaten Aspekte und Polaritäten in getrennten Schritten und fügen diese dann satzbasiert zusammen, indem sie davon ausgehen, dass in einem Satz nur eine Meinung zu einem Aspekt geäußert wird, was in vielen Fällen auch funktioniert. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übungen\n",
    "\n",
    "### 1. Prüfen Sie Ihr Wissen:\n",
    "- Warum ist es für viele Anwendungen wichtig, auch die bewerteten Aspekte zu erkennen?\n",
    "- Welche Möglichkeiten gibt es, ein Phrasen-Lexikon für Aspekte einer Domäne aufzustellen?\n",
    "- Welche Möglichkeiten gibt es, Aspekte im Text zu identifizieren?\n",
    "- Wie kann man die extrahierten Informationen über Sentiment und Aspekt zusammenführen?\n",
    "\n",
    "### 2. Setzen Sie Ihr neues Wissen ein:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Nehmen Sie das GermEval-2017-Korpus und extrahieren Sie daraus die  Aspekte aus dem Eintrag \"<Opinion category=\\... \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Extrahieren Sie die Targets für die Aspekte aus den GermEval-Daten. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) Erweitern Sie Ihre Phrasenliste mit Wörtern aus den GermEval-Texten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) Erweitern Sie Ihre Phrasenliste mit weiteren Wörtern, z. B. mit der Methode PMI, mit Synonymen aus OdeNet oder mit Word Embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e) Überarbeiten Sie die Target-Listen. Sehen Sie sich dabei besonders die Mehrwortlexeme an.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (f) Schreiben Sie eine Funktion, die - wenn sie im Text ein Target findet - den Text mit dem dazugehörigen Aspekt markiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (g) Identifizieren Sie Aspekt und Sentiment im Satz und führen Sie beides in einer Ausgabe zusammen, etwa so:\n",
    "\n",
    "aspect_and_sentiment(\"heut morgen schon im Zug die fahrt endet nie , wie weit würde es den bis zur Hölle dauern ? \\# Germany \\# Bahn \\# Silvester =D\")\n",
    "\n",
    "# mit der Ausgabe:\n",
    "# ASPECT: Zugfahrt#Fahrtzeit_und_Schnelligkeit POLARITY: negative\n",
    "\n",
    "# Im Fall von Texten mit \"aber\" trennen Sie die Texte und geben Aspekt und Sentiment für die beiden Teile getrennt an, etwa so:\n",
    "\n",
    "aspect_and_sentiment(\"@lokfuehrer_tim Schönen Feierabend! Ich bin heute zwar langsam, aber pünktlich ca. 225 km Bahn in 4 Stunden gefahren ...\")\n",
    "\n",
    "# mit der Ausgabe:\n",
    "# ASPECT: Zugfahrt#Fahrtzeit_und_Schnelligkeit POLARITY: negative\n",
    "# ASPECT: Pünktlichkeit POLARITY: positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (h) Versuchen Sie, die Dependenzanalyse von spaCy zu nutzen, um Aspekt und Sentiment zusammen zu führen, etwa so:\n",
    "\n",
    "aspect_and_sentiment_spacy(\"Das ist die doofe Bahn.\")\n",
    "\n",
    "# mit der Ausgabe:\n",
    "# ASPECT: Allgemein#Haupt POLARITY: negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reflexion in Gruppenarbeit:\n",
    "Überlegen Sie sich eine Domäne für Sätze in Ihrem Gold-Standard. Nehmen Sie in Ihren gemeinsamen Gold-Standard Sätze auf, die Aspekte dieser Domäne bewerten. Erkennt Ihre Software diese Sätze? Vergleichen Sie die Lösungen miteinander. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weiterführende Literatur\n",
    "\n",
    "In der GermEval Shared Task von 2017 haben von acht teilnehmenden Gruppen nur zwei an Task C (Identifizierung des Aspekts) teilgenommen: Eine Gruppe der TU Darmstadt (Lee et al. 2017)  und eine Gruppe aus Indien (Mishra et al. 2017). Wojatzki et al. (2017) beschreiben jedoch, dass beide nicht sehr erfolgreich waren:\n",
    "\n",
    "*\"Only (Lee et al., 2017) could outperform both provided\n",
    "baselines on the synchronic data. However, the\n",
    "improvements of 0.001 for aspect classification\n",
    "and 0.03 for aspect and sentiment classification\n",
    "are only slight.\"*\n",
    "\n",
    "Eine multilinguale Shared Task für aspektbasierte Sentiment-Analyse war Teil der SemEval-Aktivitäten im Jahr 2016 (Pontiki et al. 2016). 29 internationale Gruppen haben am Wettbewerb teilgenommen. Deutsche Sprache war leider nicht Teil der Aufgaben.\n",
    "\n",
    "Schouten und Frasincar (2016) geben einen sehr umfassenden Überblick über die verschiedenen Lösungsansätze, die Forschungsgruppen für das Problem gefunden haben. Zu Methoden der Anaphern-Auflösung geben Sukthanker et al. (2018) einen umfassenden Überblick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
