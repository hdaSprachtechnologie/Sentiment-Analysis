{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 4: Wörter in der Sentiment-Analyse\n",
    "\n",
    "Wir haben schon gesehen, dass in der Sentiment-Analyse Wörter und \n",
    "Wortlisten eine große Rolle spielen. Ein wichtiger Teil der Arbeiten ist \n",
    "es daher, die Abdeckung zu erweitern, also mehr bewertende Wörter zu \n",
    "erkennen. Dies sind vor allem Adjektive wie \"schlecht\", \"schön\", \n",
    "\"schnell\" oder \"robust\". Aber auch Mehrwortlexeme spielen eine \n",
    "Rolle, wie \"geht schnell kaputt\" oder \"bringt mich um den \n",
    "Verstand\". Der Kontext der Wörter kann dabei sehr wichtig sein, wie \n",
    "man bei \"schnell\" und \"geht schnell kaputt\" sehen kann. \n",
    "Um Wörter abgleichen zu können, müssen die Texte zunächst normalisiert werden. Der Rest des Kapitels beschäftigt sich mit der Gewinnung von Wörtern für Wortlisten in der Sentiment-Analyse. Wir zeigen die Option auf, existierende Wortlisten einzubinden, WordNet als Quelle zu nutzen, Wörter aus annotierten Textkorpora zu extrahieren und Wörter aus nicht-annotierten Textkorpora zu extrahieren. \n",
    "\n",
    "## Normalisierung der Texte\n",
    "\n",
    "Eine bessere Erkennung der meinungsausdrückenden Wörter lässt sich \n",
    "zunächst damit erreichen, dass die Texte vereinheitlicht werden. Zwei \n",
    "wichtige Schritte sind hier zu nennen: Textnormalisierung und \n",
    "Lemmatisierung. Bei der Textnormalisierung schreibt man alle Wörter im \n",
    "Text (und in den Wortlisten) mit Kleinbuchstaben und löscht alle \n",
    "Bindestriche und Sonderzeichen, um sie besser vergleichen zu können. \n",
    "\n",
    "Hier ist noch einmal das Beispiel aus dem GermEval 2017 Korpus:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Deutsche Bahn - Eine Horrorgeschichte Darf jetzt erstmal zum nächsten Bahnhof laufen, weil der Zug auf der Strecke stehengeblieben ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die normalisierte Version davon ist:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "deutsche bahn eine horrorgeschichte darf jetzt erstmal zum nächsten bahnhof laufen, weil der zug auf der strecke stehengeblieben ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ersetzung von Sonderzeichen wie Emojis, die zum Absturz von \n",
    "Python-Programmen führen können, kann z. B. mit diesem Code-Schnipsel \n",
    "realisiert werden: \n",
    "\n",
    "(https://frageit.de/questions/45715280/ucs2-codec-cant-encode-characters-in-position-6161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmp(s):\n",
    "    return \"\".join((i if ord(i) < 10000 else '\\ufffd' for i in s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einigen Fällen kann es jedoch sinnvoll sein, Emojis zu untersuchen \n",
    "und nicht zu ignorieren. Dafür gibt es z. B. das Python-Modul \n",
    "*emoji* (https://pypi.org/project/emoji/).\n",
    "\n",
    "Bei der Lemmatisierung führen wir alle Wörter auf ihre Grundform (Lemma) zurück \n",
    "und müssen dann nicht mehr \"gutes\", \"guter\", \"gute\" in die \n",
    "Wortlisten aufnehmen, sondern nur noch \"gut\". Damit geht Information \n",
    "über die Satzsyntax allerdings verloren, sodass man genau überlegen \n",
    "muss, an welcher Stelle dieser Schritt eingesetzt wird.\n",
    "\n",
    "Für die Lemmatisierung haben Programme wie TextBlob und spaCy (https://spacy.io/) eigene \n",
    "Module, die in den meisten Fällen auf einfachen Wortlisten basieren, die \n",
    "den Wörtern ihre Lemmata zuordnen. \n",
    "\n",
    "Die lemmatisierte Version ist nun:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "deutschen bahn einen horrorgeschichte dürfen jetzt erstmal zum nächst bahnhof laufen, weil der zug auf der strecke stehenbleiben sein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einbindung eines existierenden Sentiment-Wörterbuchs\n",
    " \n",
    "Eine weitere gute Möglichkeit, mehr lexikalische Einheiten zu erkennen, \n",
    "ist, existierende Wortlisten einzubinden. In Forschungsprojekten der \n",
    "letzten Jahre sind Listen von Wörtern und Phrasen entstanden, die frei \n",
    "zur Verfügung stehen und in neue Systeme eingebunden werden können. \n",
    "Auf der IGGSA-Webseite (https://sites.google.com/site/iggsahome/downloads) sind einige dieser Ressourcen gelistet. Hier sollen \n",
    "nur ein paar Beispiele genannt werden, denn es kommen ständig neue \n",
    "Ressourcen hinzu:\n",
    "\n",
    "Die \"SePL (Sentiment Phrase List)\" der Universität Hof wird bei \n",
    "Rill et al. (2012) beschrieben. Die Liste kann über die \n",
    "Projektwebseite (http://www.opinion-mining.org/SePL-Sentiment-Phrase-List) angefordert werden. Sie enthält über 14.000 Einträge im \n",
    "csv-Format, die aus Produktbewertungen mit ihrer Sternewertung \n",
    "automatisch erzeugt und zum Teil von Hand korrigiert wurden. \n",
    "\n",
    "Ein paar Beispiele aus dieser Liste:\n",
    "\n",
    "| phrase | opinion value | standard deviation | standard error | phrase type | manual correction |\n",
    "|--------|---------------|--------------------|----------------|-------------|-------------------|\n",
    "| abartig | -0.540        | 0.811              | 0.186          | a           |                   |\n",
    "| abermals bestens gelungen | 0.800 | 0.000 | 0.000  | a | m |\n",
    "| abgedreht | 0.000 | 0.000  | 0.000 | a | m |\n",
    "\n",
    "Das \"Polarity Lexicon\" der Universität Zürich \n",
    "(Clematide und Klenner 2010) enthält ca. 8400 Einträge. Diese Einträge sind - mit ihren Polaritätswerten - manuell erzeugt worden.\n",
    "Zwei Beispiele aus dieser Liste:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pittoresk NEG=1\n",
    "polemisch NEG=0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Basis dieser Wortliste sind literarische Texte, also eine ganz \n",
    "andere Textsorte als die Produktbewertungen der SePL. \n",
    "\n",
    "Das \"Multi-Domain Sentiment Lexicon for German\" (https://sites.google.com/site/iggsahome/downloads/OPM.zip?attredirects=0) der Hochschule \n",
    "Darmstadt ist aus einem studentischen Projekt entstanden, in dem die \n",
    "lexikalischen Daten aus drei verschiedenen Wortlisten kombiniert wurden. \n",
    "Es enthält ca. 2900 Einträge im XML-Format. Hier ist ein Auszug:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " <entry>\n",
    "      <term>menschlich</term>\n",
    "      <opinion source=\"pressrelease dataset\" polarity=\"1.0\" />\n",
    "      <opinion source=\"MLSA\" polarity=\"0.0\" />\n",
    "      <opinion source=\"SentiWS\" polarity=\"0.3324\" />\n",
    "  </entry>\n",
    " \n",
    " <entry>\n",
    "      <term>schlecht</term>\n",
    "      <opinion source=\"pressrelease dataset\" polarity=\"-0.8333333\" />\n",
    "      <opinion source=\"MLSA\" polarity=\"-0.11111111\" />\n",
    "      <opinion source=\"SentiWS\" polarity=\"-0.7706\" />\n",
    "  </entry>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Zusammenführung fiel auf, dass die Polaritätswerte der drei Ressourcen sich teilweise ganz wesentlich unterscheiden. Das ist einerseits darauf zurückzuführen, dass bei manuellen Annotationen unterschiedliche Standards angenommen werden, so wie \"+, -, 0\" oder Fließkommazahlen, und andererseits darauf, dass für ganz unterschiedliche Domänen gearbeitet wurde. So ist z. B. der Terminus \"gerecht\" im politischen Kontext als stark positiv und im wirtschaftsorientierten Kontext nur leicht positiv annotiert.\n",
    "\n",
    "Bei der Auswahl einer Wortliste für die Integration ist es wichtig, die thematische \n",
    "Domäne zu beachten, denn literarische Texte können ganz andere \n",
    "bewertende Wörter enthalten als z. B. Social-Media-Bewertungen. Darüber \n",
    "hinaus müssen verschiedene Formate (CSV, Tabellen, XML, ...) in das \n",
    "Format überführt werden, das in der eigenen Implementierung gebraucht \n",
    "wird. Schulz et al. (2017) beschreiben, wie sie in künftigen Implementierungen die Wörterbücher für spezielle Domänen aufbauen wollen:\n",
    "\n",
    "*A major improvement for the future would be to create\n",
    "a domain-dependent sentiment lexicon in order\n",
    "to capture specific words and phrases which in this\n",
    "particular context have a stronger polarity than in\n",
    "others.*\n",
    "\n",
    "(Deutsch: *Eine wesentliche Verbesserung für die Zukunft wäre die Schaffung eines domänenabhängigen Sentiment-Lexikons, um bestimmte Wörter und Phrasen zu erfassen, die in diesem speziellen Kontext eine stärkere Polarität aufweisen als in anderen.* (eigene Übersetzung))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gewinnung von Sentiment-Wörtern mithilfe von WordNet\n",
    "\n",
    "WordNet ist eine linguistische Ressource, die seit den 90er Jahren \n",
    "entwickelt wird (Fellbaum 1998). Die lexikalischen \n",
    "Einträge sind in Synonym-Gruppen - sogenannten \"Synsets\" - \n",
    "organisiert. Zwischen den Synsets sind Beziehungen wie Hyponymie und \n",
    "Antonymie definiert. Dazu kommen weitere Informationen, wie Definitionen \n",
    "und Sprachbeispiele.\n",
    "\n",
    "Zunächst für die englische Sprache entwickelt, kamen weitere WordNets \n",
    "für viele andere Sprachen hinzu (Bond 2012), \n",
    "die in einer globalen Initiative miteinander verknüpft wurden \n",
    "(Bond 2016). Die Ressource wurde für viele \n",
    "sprachtechnologische Anwendungen genutzt, so auch für die Entwicklung \n",
    "und Erweiterung von Wörterbüchern zur Sentiment-Analyse. \n",
    "\n",
    "Hu und Liu (2004) beschreiben, dass sie eine kleine Menge \n",
    "englischer Adjektive von Hand als positiv oder negativ bewertet haben \n",
    "und dann für diese Adjektive zunächst die Synonyme aus WordNet gesucht \n",
    "haben. Im nächsten Schritt haben sie die Antonyme mit dem jeweils \n",
    "gegensätzlichen Wert bewertet und davon wiederum Synonyme gesucht. Das \n",
    "Opinion Lexicon (http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\#lexicon) enthält damit 6800 englische Adjektive, die als positiv \n",
    "und negativ klassifiziert sind. \n",
    "\n",
    "Baccianella et al. (2010) sind ähnlich vorgegangen, haben \n",
    "dann aber die Klassifikation direkt im WordNet aufgenommen, das WordNet \n",
    "also erweitert. Dabei haben sie auch die Adjektive in Definitionen für \n",
    "die Synsets mit derselben Polarität annotiert wie das Synset selbst.\n",
    "\n",
    "Naderalvojoud et al. (2017) testen drei verschiedene Sentiment-Lexika im Zusammenhang mit einer Analyse auf der Basis von  \"Recurrent Neural Networks\" (RNN) und stellen fest, dass das auf WordNet basierte Lexikon SWN am besten funktioniert: \n",
    "\n",
    "*Furthermore, while the German SentiSpin lexicon does\n",
    "not improve the performance of the RNN model\n",
    "in the positive class, the proposed German SWN\n",
    "lexicons significantly improve its performance.*\n",
    "\n",
    "(Deutsch: *Während das deutsche SentiSpin-Lexikon die Leistung des RNN-Modells in der positiven Klasse nicht verbessert, verbessern die vorgeschlagenen deutschen SWN-Lexika ihre Leistung deutlich.* (eigene Übersetzung))\n",
    "\n",
    "\n",
    "Da auch WordNets für andere Sprachen als das Englische existieren, wie \n",
    "z. B. OdeNet (https://github.com/hdaSprachtechnologie/odenet) für die deutsche Sprache, sind diese Methoden übertragbar. \n",
    "Der Vorteil davon ist, dass man recht schnell zu einer großen Liste \n",
    "klassifizierter Wörter kommt. Es fehlt aber die Anpassung an die Domäne, \n",
    "die Gegenstand der Implementierung ist.\n",
    "\n",
    "Hier sind Synonyme zu \"gut\" aus OdeNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyme_gut = ['1a', 'O. K.', 'Seele von Mensch', 'abgemacht', 'akzeptiert', 'alles klar', 'alles paletti', 'angenehm', 'charmant', \"d'accord\", 'da sage ich nicht nein', 'das ist ein Wort', 'dein Wille geschehe', 'dienlich', \n",
    "'eins a', 'einverstanden', 'erbaulich', 'erfreulich', 'ergötzlich', 'erhebend', 'erquicklich', 'ersprießlich', 'es geschehe nach deinen Worten', 'es sei', 'fein', 'fruchtbar', 'förderlich', 'gebongt', \n",
    "'gedeihlich', 'gefreut', 'geht in Ordnung', 'geht klar', 'gemacht', \n",
    "'genehmigt', 'gewinnbringend', 'glücklich', 'gutmütig', 'günstig', \n",
    "'gütig', 'herzensgut', 'herzerfrischend', 'herzerquicklich', \n",
    "'hilfreich', 'ich nehme dich beim Wort', 'ist recht', 'lohnend', 'machen wir', 'manierlich', 'menschlich', 'nutzbringend', 'nutzwertig', \n",
    "'nützlich', 'o. k.', 'okay', 'okey-dokey', 'opportun', 'pläsierlich', \n",
    "'positiv', 'roger', 'sachdienlich', 'schon überredet', 'schön', \"so machen wir's\", 'so sei es', 'sympathisch', 'tadellos', 'trefflich', 'von Nutzen', 'von Vorteil', 'von guter Qualität', 'vorteilhaft', 'warum nicht', 'wertvoll', 'wohl', 'wohltuend', 'zuträglich']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synonyme zu \"schlecht\" aus OdeNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyme_schlecht = ['(jemand) hätte mehr erwartet', 'Billig...', 'Hinterhof-...', \n",
    "'Hintertreppen-...', 'Hobby-...', 'Küchen-...', 'Möchtegern-', \n",
    "'Provinz-...', 'Wald- und Wiesen-...', 'am Boden', 'am Tiefpunkt', \n",
    "'amateurhaft', 'arg', 'ausbaufähig', 'bedenklich', 'bescheiden', \n",
    "'beschissen', 'billig', 'bitter', 'blöd', 'bös', 'bösartig', 'böse', \n",
    "'böswillig', 'derb', 'dilettantenhaft', 'dilettantisch', 'drittklassig', \n",
    "'dumm', 'dürftig', 'eher nicht', 'eher weniger', 'ernstlich', 'es gibt Entwicklungsbedarf', 'etwas Dummes', 'fadenscheinig', 'fies', 'flach', \n",
    "'ganz unten', 'gemein', 'geringwertig', 'gut gemeint, aber schlecht gemacht', 'gut gewollt, aber schlecht gekonnt', 'halbwertig', 'hapern mit', 'hart', 'hobbyhaft', 'im Keller', 'insuffizient', 'kaum', \n",
    "'laienhaft', 'lausig', 'leidig', 'lästig', 'mangelhaft', 'mau', \n",
    "'medioker', 'mies', 'minderer Güte', 'minderwertig', 'misslich', \n",
    "'mäßig', 'nachteilig', 'negativ', 'nicht (besonders) ambitioniert', \n",
    "'nicht ausreichend', 'nicht besonders einfallsreich', 'nicht den Erwartungen entsprechen', 'nicht ernst zu nehmen', 'nicht erwünscht', \n",
    "'nicht genug', 'nicht in Ordnung', 'nicht rosig', 'nicht so gut', 'nicht so richtig', 'nicht wirklich', 'nicht wünschen', 'nicht wünschenswert', \n",
    "'niveaulos', 'ohne Ambition', 'ohne Anspruch', 'ohne Niveau', 'platt', \n",
    "'prekär', 'primitiv', 'schlechter Qualität', 'schlimm', 'schmerzlich', \n",
    "'schmerzvoll', 'schrecklich', 'schwach', 'schwer', 'schwer zu ertragen', \n",
    "'schwerlich', 'schädlich', 'seicht', 'steigerungsfähig', 'störend', \n",
    "'stümperhaft', 'unambitioniert', 'unangenehm', 'unbequem', \n",
    "'unerfreulich', 'unerquicklich', 'unerwünscht', 'ungenügend', 'ungut', \n",
    "'ungünstig', 'unliebsam', 'unmöglich', 'unprofessionell', \n",
    "'unqualifiziert', 'unschön', 'unter Soll', 'unwillkommen', \n",
    "'unzulänglich', 'unzureichend', 'vermutlich kaum', 'vermutlich nicht', \n",
    "'von Nachteil', 'wahrscheinlich kaum', 'wahrscheinlich nicht', 'wenig beneidenswert', 'widrig', 'wie in einem schlechten Film', 'wohl kaum', \n",
    "'wohl nicht', 'zu wenig', 'zu wünschen übrig lassen', 'zweiten Ranges', \n",
    "'zweitklassig', 'ärgerlich', 'übel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird deutlich, dass diese Methode geeignet ist, um die Wortlisten der \n",
    "allgemeinen Sentiment-Wörter zu erweitern. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gewinnung von Sentiment-Wörtern aus annotierten Korpora\n",
    "\n",
    "Eine gute Methode, um Sentiment-Wörter zu gewinnen, die in der Domäne \n",
    "relevant sind, ist, sie aus einem annotierten Textkorpus automatisch zu \n",
    "extrahieren. Wenn man z. B. ein Sentiment-Analyse-Tool entwickeln möchte, \n",
    "das Texte aus sozialen Medien zum Thema \"Bahn\" analysieren soll, \n",
    "könnte man die annotierten Daten der GermEval \n",
    "Shared Task 2017 (https://sites.google.com/view/germeval2017-absa/data) zugrunde legen. Diese Daten sind frei verfügbar, als tsv- und als xml-Datei. Jeder Text ist u.a. mit der Polarität der \n",
    "Meinungsäußerung annotiert. Im ersten Schritt werden die positiven, \n",
    "negativen und neutralen Texte in getrennten Dateien gesammelt. Um dafür \n",
    "das XML-Format zu verarbeiten, empfiehlt sich die  *ElementTree XML \n",
    "API* (https://docs.python.org/3/library/xml.etree.elementtree.html). Für das tsv-Format kann man das  *CSV-Modul* von Python verwenden (https://docs.python.org/3/library/csv.html).\n",
    "\n",
    "Nach Tokenisierung und Lemmatisierung extrahiert man alle Wörter aus den \n",
    "negativen, alle Wörter aus den positiven und alle Wörter aus den \n",
    "neutralen Sätzen und subtrahiert die Listen voneinander. Das Ergebnis \n",
    "davon ist allerdings noch nicht zufriedenstellend. So beginnt die Liste \n",
    "der positiven Wörter, die damit aus dem GermEval-Korpus extrahiert \n",
    "wurden, folgendermaßen:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'chauffiert', 'putzig', 't.co/lPJOlehVTB', 'Stratenschulte', 'Rückmeldung', 'ndr', 'Erleichterung', 'einwandfrei', 'Kompliment', 'abfragen', 'dramatisch', 'Entertainmentsystem', '1:40', 'HobbyIngenieur', '09:37:00', 'businesstraveller.de', 't.co/ZO9QnFqUYF', 'Idealfall', 'Jaaa', 'Storno', 'Ticket-Funktionalität', 'QR-Lesegeräte', 'denk', 't.co/Hbms3Ya9xa', 'Lokführer-Streiks', 'Handyticket', 'Heimweg', 'Mdr.de', 'kürzen', 'Niederschelderhütte', 'flyingdutchy04', 'Göleli', 'Einsatzplaner', 'weiere', 'Bahn-Streiks', 'gemach', \n",
    "'Frühjahr', 'deinstallieren', 'schluden', 'feierlich', 'Tarifkompromiss', 'punkt', 'Halim', '10:18:00', 'Herrlich',..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es scheint also sinnvoll zu sein, in erster Linie Adjektive zu \n",
    "extrahieren. Die bereits erwähnten Module TextBlob und spaCyhaben einen \n",
    "\"Part-of-Speech-Tagger\", der die syntaktischen Kategorien der Wörter \n",
    "im Text bestimmt. Für die  GermEval-Daten sind einige der auf diese Weise \n",
    "extrahierten Adjektive:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Positive:\n",
    "'fair', 'feierlich', 'Herrlich', 'wirksam', 'Hoch', 'dramatisch', 'einwandfrei', 'unverzüglich', 'rheinisch', \n",
    "'klimafreundlichen', 'strahlend', 'Herchen', 'kundenfreundlich', 'sanieren', 'machbar', 'Mitteldeutsche', 'skeptisch', 'legitim', 'hiesig', 'Rheinische', 'Mittelbahnsteig', 'einigen', 'wier', 'prompt', 'Zeig', 'einfach/Langweilig', 'Hausbahnsteig', 'hilfreich', 'mollig', 'Windeck-Herchen', 'idyllisch', 'perfekt', 'Weltweit', 'merkwürdig', 'wiedersprechen', 'kölnisch'\n",
    "\n",
    "Negative:\n",
    "'Steig', 'spezial', 'rücksichtslos', 'Umweltschonend', 'misstrauisch', 'unterhaltsam', 'selbstverständlich', \n",
    "'aggressiv', 'nachfolgend', 'heilig', 'anwesend', 'Munchen', 'Islam', 'lächerlich', 'entgegengesetzt', 'Dulig', 'monatelang', 'blechen', 'Einzige', 'endgültig', 'unsinnig', 'Menschenfeindlich', 'konkret', 'geschützt', 'bundesdeutsch', 'unverschämt', 'Mutmaßliche', 'wildrotierend', 'S-Bahnsteig', 'ernsthaft', 'Tatsächlich', 'fähig', 'Groß', 'mutig', 'heldenhaft', 'Weitere', 'exklusiv', 'Möglich', 'Völlig', 'verscheuchen', 'Fremdenfreundlich', 'vorübergehen', 'leid', 'voraussichtlich', 'unbeständig', 'erkennbar', 'stündlich', 'belgisch', 'ärgerlich', 'dreiteilig', 'stressig', 'Regional', 'verbunden'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einerseits wird deutlich, dass diese Listen überarbeitet werden müssen, \n",
    "bevor man die Wörter ins Sentiment-Wörterbuch übernehmen kann. \n",
    "Andererseits wird aber auch deutlich, dass auf diese Weise bewusste oder \n",
    "unbewusste Falschschreibungen der Social-Media-AutorInnen auftreten, die speziell für die Textsorte \n",
    "\"Soziale Medien\" sind und in Standard-Wortlisten nicht enthalten \n",
    "sind, wie \"unzufärläsig\" oder \"verhungertambahnsteig\". Diese sind für eine gute Erkennung äußerst relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gewinnung von Wörtern aus nicht annotierten Korpora\n",
    "\n",
    "Im Internet sind sehr große Mengen an Text in sehr vielen Sprachen \n",
    "verfügbar. Dies ist eine enorme Chance, um Wortlisten zu gewinnen. Da \n",
    "diese Texte jedoch nicht annotiert sind, versucht man, andere Methoden \n",
    "zu finden, um Wörter zu klassifizieren. \n",
    "\n",
    "Eine Methode ist die \"Pointwise Mutual Information Measure (PMI)\". \n",
    "Sie basiert darauf zu erkennen, welche Wörter häufig mit bestimmten \n",
    "vorklassifizierten Wörtern (wie  \"gut\" oder \"schlecht\") auftreten \n",
    "und nutzt eine Suchmaschine dafür als Basis.\n",
    "\n",
    "PMI berechnet sich aus der Wahrscheinlichkeit des gemeinsamen Auftretens \n",
    "zweier Terme:\n",
    "\n",
    "$PMI (term_1, term_2) = log_2 (\\frac{Pr(term_1 \n",
    "\\bigwedge term_2)}{Pr(term_1)Pr(term_2)} )$\n",
    "\n",
    "Dabei ist $Pr (term_1 \\bigwedge term_2)$ die Wahrscheinlichkeit, dass \n",
    " $term_1$ und $term_2$ zusammen im Satz auftreten und $Pr (term_1) Pr \n",
    "(term_2)$ die Wahrscheinlichkeit, dass $term_1$ und $term_2$ (unabhängig \n",
    "voneinander) auftreten. Der Logarithmus in der Formel dient dazu, besser \n",
    "darstellbare Zahlen zu bekommen, die weder extrem niedrig noch extrem \n",
    "hoch sind.\n",
    "\n",
    "Mit der Suchmaschine google ergibt sich so ein PMI-Wert für die Wörter \n",
    " \"gut\" und  \"super\" von 8,61, für die Wörter \"gut\" und \n",
    " \"kalt\" von 1,22. Es wäre also denkbar, aus Texten in der Domäne alle \n",
    "Adjektive zu filtern und mit den PMI-Werten für ihre Kombination mit \n",
    " \"gut\" und \"schlecht\" ihre Polarität zu bestimmen. \n",
    " \n",
    " Eine andere Methode ist die der sogenannten  \"Word Embeddings\"\n",
    "(Mikolov 2013). Die grundlegende Idee ist, dass \n",
    "semantisch ähnliche Wörter in ähnlichen Kontexten auftreten. Um diese \n",
    "Kontexte mit maschinellen Lernverfahren trainieren zu können, werden \n",
    "Vektoren aufgestellt. Dabei wird jedes Wort durch einen Vektor \n",
    "repräsentiert, der für jedes andere Wort im Korpus einen Zahlenwert \n",
    "enthält. Dieser Zahlenwert ist die Wahrscheinlichkeit, mit der das \n",
    "aktuelle Wort in einem definierten Kontext mit dem Wort aus dem Korpus \n",
    "zusammen auftritt. Nehmen wir zur Illustration des Verfahrens diesen Mini-Textkorpus mit \n",
    "vier Sätzen:\n",
    "- Die schwarze Katze miaut. \n",
    "- Die schwarz-weiße Katze frisst.\n",
    "- Der schwarze Hund miaut.\n",
    "- Der schwarz-weiße Hund frisst.\n",
    "\n",
    "Es gibt im Textkorpus 8 verschiedene Wörter:\n",
    "\n",
    "[die, schwarze, katze, miaut, schwarz-weiße, frisst, der, hund]\n",
    "\n",
    "Daher bekommt jedes Wort einen Indexwert, der zwischen 1 und 8 liegt:\n",
    "- die: 1\n",
    "- schwarze: 2\n",
    "- katze: 3\n",
    "- miaut: 4\n",
    "- schwarz-weiße: 5\n",
    "- frisst: 6\n",
    "- der: 7\n",
    "- hund: 8\n",
    "\n",
    "Der Satz *Der schwarze Hund miaut* wird als ein Vektor \n",
    "repräsentiert, der eine 4x8-Matrix ist:\n",
    "\n",
    "|   |   |\n",
    "|-----|-------|\n",
    "| der |  0 0 0 0 0 0 1 0 |\n",
    "| schwarze |  0 1 0 0 0 0 0 0 |\n",
    "| hund |  0 0 0 0 0 0 0 1 |\n",
    "| miaut |  0 0 0 1 0 0 0 0 |\n",
    "\n",
    "\n",
    "Nun gilt es zu beachten, dass man diese Methode auf große Textkorpora \n",
    "mit mehreren tausend Wörtern anwendet, sodass die Matrix extrem groß \n",
    "wird. Mit einem Algorithmus mit dem Namen  \"word2vec\" (Mikolov 2013) wird der Vektor \n",
    "auf weniger Dimensionen reduziert und dabei dennoch der Kontext \n",
    "erhalten. Für jedes Wort wird berechnet, welche Wörter am \n",
    "wahrscheinlichsten davor und dahinter stehen. Das Kontextfenster kann \n",
    "dabei verschoben werden. Meistens ist dieses Fenster fünf Wörter groß, also \n",
    "zwei davor und zwei dahinter. Für ein Wort bekommen dann die Wörter ein \n",
    "höheres Gewicht, die häufig in diesem Fenster zusammen mit dem Wort \n",
    "auftreten. \n",
    "\n",
    "Mit dieser Methode kann dann eine Wortliste mit Wörtern aus der Domäne \n",
    "erweitert werden, wenn ausreichend Textmaterial vorhanden ist, das aber \n",
    "nicht annotiert sein muss. Die Vektoren können aber im Zusammenhang mit annotierten Daten auch direkt für die Sentiment-Analyse mit Deep-Learning-Verfahren genutzt werden.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "Wortlisten sind zentral für die Sentiment-Analyse, egal ob diese statistisch oder regelbasiert ist. Dieses Kapitel hat sich damit befasst, wie Wortlisten genutzt oder aufgestellt werden können. Eine Textnormalisierung ist dafür die Grundvoraussetzung, vor allem wenn wir mit Social-Media-Daten arbeiten. Eine Option, um an Wortlisten zu kommen, ist die Übernahme und ggf. Anpassung eines existierenden Sentiment-Lexikons. Dabei muss beachtet werden, dass die Polaritätswerte der einzelnen Lexika zum Teil erheblich voneinander abweichen und dass die Lexika auf sehr unterschiedlichen Daten basieren. Eine weitere Option ist die Nutzung von WordNet-Einträgen, die in Synonym-Mengen organisiert sind. Domänenspezifische Sentiment-Wörter bekommt man, indem man sie aus Korpora der jeweiligen Domäne extrahiert. Es gibt Methoden, die annotierte Korpora verwenden, aber auch solche, die mit nicht annotierten Korpora arbeiten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weiterführende Literatur\n",
    "Existierende Sentiment-Wörterbücher für die deutsche Sprache, die in eine Implementierung eingebunden werden können, sind auf der IGGSA-Webseite https://sites.google.com/site/iggsahome/downloads zu finden. Die Beiträge im Tagungsband der GermEval 2017 zeigen, wie diese in verschiedene Systeme eingebunden worden sind. \n",
    "Naderalvojoud et al. (2017) sind einen anderen Weg gegangen, indem sie existierende englischsprachige Sentimentwörterbücher automatisch ins Deutsche übersetzt haben. Hu und Liu (2004) und Baccianella et al. (2010) sind Beispiele für den WordNet-Ansatz. Das Standardwerk für Word Embeddings ist Mikolov (2013). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übungen\n",
    "\n",
    "### Prüfen Sie Ihr Wissen\n",
    "\n",
    "- Welche Möglichkeiten der Textnormalisierung gibt es?\n",
    "- Was sind die Herausforderungen bei der Einbindung existierender Wörterbücher?\n",
    "- Was ist WordNet und wie kann man die Ressource für die Sentiment-Analyse nutzen?\n",
    "- Welche Möglichkeiten zur Gewinnung von Sentiment-Wörtern aus annotierten Korpora gibt es?\n",
    "- Welche Möglichkeiten zur Gewinnung von Sentiment-Wörtern aus nicht annotierten Korpora gibt es?\n",
    "\n",
    "### Setzen Sie Ihr neues Wissen ein\n",
    "\n",
    "Vergrößern Sie die Abdeckung Ihres Sentiment-Wörterbuchs durch Normalisierung:\n",
    "- Reduzieren Sie Ihr Sentiment-Wörterbuch so, dass nur noch Lemmata darin stehen.\n",
    "- Verändern Sie den Wortlistenvergleich, indem Sie die kleingeschriebenen Lemmata der Wörter im Text und im Wörterbuch miteinander vergleichen. Die Lemmatisierung kann z. B. mit spaCy oder TextBlob geschehen.\n",
    "\n",
    "Recherchieren Sie Sentiment-Wortlisten für die deutsche Sprache und integrieren Sie die gefundenen Wörter in Ihr Wörterbuch.\n",
    "\n",
    "Vergrößern Sie Ihr Sentiment-Wörterbuch durch WordNet-Ressourcen:\n",
    "- Recherchieren Sie die multilingualen WordNets und OdeNet. Sehen Sie sich die Daten an und diskutieren Sie, wie man diese in der Sentiment-Analyse nutzen kann.\n",
    "- Fügen Sie die Synonyme zu \\enquote{gut} und \\enquote{schlecht} aus OdeNet in Ihr Wörterbuch der Sentiment-Wörter ein und testen Sie dann die Sätze aus Ihrem Gold-Standard.\n",
    "- Die Liste enthält auch Mehrwortlexeme. Fügen Sie Ihrem Gold-Standard Sätze mit solchen Mehrwortlexemen hinzu. Sehen Sie Möglichkeiten, mit Mehrwortlexemen umzugehen?\n",
    "\n",
    "Nehmen Sie den Korpus der GermEval 2017 zur Hand und extrahieren Sie daraus negative und positive Adjektive. Erweitern Sie damit Ihr Lexikon.\n",
    "\n",
    "Vergrößern Sie Ihr Sentiment-Wörterbuch mit Word Embeddings:\n",
    "- Für ein kleines Trainingsexperiment nehmen Sie die Installation von Nathan Rooy und passen Sie sie für unser Spielzeugbeispiel von oben an: https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/\n",
    "- Aufgrund der großen Datenmengen, die benötigt werden und der riesigen Vektoren, die dabei entstehen, benutzen wir ein bereits vortrainiertes Modell für unsere Experimente. Die Universität Heidelberg stellt unter https://www.cl.uni-heidelberg.de/english/research/downloads/resource_pages/GermanTwitterEmbeddings/GermanTwitterEmbeddings_data.shtml ein Modell von Word Embeddings zur Verfügung, das auf deutschsprachigen Twitterdaten aus den Jahren 2013 bis 2017 trainiert worden ist. Laden Sie das Modell herunter, entpacken Sie die gz-Datei und importieren Sie sie:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst importieren Sie gensim, mit dem man auf das Modell zugreifen kann. Das Limit beim Import des Modells ist notwendig, um Ihren Rechner nicht zu überfordern.\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = 'twitter-de_d100_w5_min10.bin'\n",
    "model = KeyedVectors.load_word2vec_format(model, binary=True, limit=50000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ähnlichkeit von Wörtern wird folgendermaßen definiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(w, top=10):\n",
    "    try:\n",
    "        for w, confidence in model.similar_by_word(w, topn=top):\n",
    "            yield w, round(confidence, 2)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können Sie schon Wörter suchen, die in ähnlichen Kontexten wie z. B. das Wort ``blöd'' auftreten. Testen Sie das mit verschiedenen Wörtern und nehmen Sie die Ergebnisse in Ihre Wortlisten auf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, v in similar(\"blöd\", 100):\n",
    "    if v >= 0.7:\n",
    "        print (v, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spannend ist es aber auch, dass wir Werte für die Ähnlichkeit von Sätzen bekommen. Das geht folgendermaßen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_pos = model.wmdistance(\"Das ist total toll\", \"Ich bin froh und stolz darauf, ein Mensch geworden zu sein, der Leuten die Bahn aufhält, Senioren beim Aussteigen hilft\")\n",
    "\n",
    "print(\"Positive Ähnlichkeit: \"+\"{:.4f}\".format(similarity_pos))\n",
    "\n",
    "similarity_neg = model.wmdistance(\"Das ist absoluter Mist\", \"Ich bin froh und stolz darauf, ein Mensch geworden zu sein, der Leuten die Bahn aufhält, Senioren beim Aussteigen hilft\")\n",
    "\n",
    "print(\"Negative Ähnlichkeit: \"+\"{:.4f}\".format(similarity_neg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versuchen Sie, so einen Wert als Feature in Ihr System zum maschinellen Lernen einzubauen und testen Sie, ob sich die Accuracy dadurch verbessert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
